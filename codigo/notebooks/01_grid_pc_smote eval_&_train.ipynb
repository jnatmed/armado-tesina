{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482b3476",
   "metadata": {},
   "source": [
    "# Evaluación de PC-SMOTE con Grid Search en el dataset Shuttle (Generación de caso base y datasets aumentados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27267283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo que hace es modificar la lista de rutas de búsqueda de módulos de Python (sys.path) para incluir las carpetas ../scripts y ../datasets como ubicaciones adicionales donde Python puede buscar módulos o paquetes cuando hacés un import.\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "sys.path.append(\"../datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810c62f",
   "metadata": {},
   "source": [
    "## Importación de módulos y librerías necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee7abae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Módulos propios del proyecto ---\n",
    "from cargar_dataset import cargar_dataset                      # Función para cargar datasets según configuración\n",
    "from config_datasets import config_datasets                    # Diccionario de configuración de datasets\n",
    "from evaluacion import evaluar_sampler_holdout                 # Evaluación de sobremuestreo con partición hold-out\n",
    "from custom_samplers import PCSMOTEWrapper                     # Wrapper personalizado para la técnica PCSMOTE\n",
    "from pc_smote import PCSMOTE                                   # Implementación principal de PCSMOTE\n",
    "\n",
    "# --- Librerías estándar de Python ---\n",
    "from datetime import datetime, timedelta                       # Manejo de fechas y tiempos\n",
    "from itertools import product                                  # Generación de combinaciones de parámetros\n",
    "import gc, os, time                                                      # Operaciones con el sistema de archivos\n",
    "\n",
    "# --- Librerías científicas ---\n",
    "import numpy as np                                              # Operaciones numéricas y algebra lineal\n",
    "import pandas as pd                                             # Manipulación y análisis de datos tabulares\n",
    "from scipy.stats import uniform                                 # Distribuciones para búsqueda de hiperparámetros\n",
    "\n",
    "# --- Scikit-learn: preprocesamiento ---\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler # Codificación de etiquetas y escalado de datos\n",
    "from sklearn.pipeline import make_pipeline, Pipeline            # Creación de pipelines de procesamiento y modelado\n",
    "\n",
    "# --- Scikit-learn: división y validación ---\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,                                           # División de datos en train/test\n",
    "    StratifiedKFold,                                            # Validación cruzada estratificada\n",
    "    RandomizedSearchCV                                          # Búsqueda aleatoria de hiperparámetros\n",
    ")\n",
    "\n",
    "# --- Scikit-learn: reducción de dimensionalidad ---\n",
    "from sklearn.decomposition import PCA                           # Análisis de Componentes Principales\n",
    "\n",
    "# --- Scikit-learn: métricas ---\n",
    "from sklearn.metrics import (\n",
    "    f1_score,                                                    # Métrica F1-Score\n",
    "    balanced_accuracy_score,                                     # Precisión balanceada\n",
    "    matthews_corrcoef,                                           # Coeficiente MCC\n",
    "    cohen_kappa_score,                                           # Kappa de Cohen\n",
    "    make_scorer                                            \n",
    ")\n",
    "\n",
    "# --- Scikit-learn: clasificadores ---\n",
    "from sklearn.ensemble import RandomForestClassifier             # Clasificador Random Forest\n",
    "from sklearn.linear_model import LogisticRegression             # Regresión logística\n",
    "from sklearn.svm import SVC                                      # Máquinas de Vectores de Soporte (SVM)\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Evitar sobre-suscripción de CPU (BLAS/OpenMP)\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc87fa1",
   "metadata": {},
   "source": [
    "### Evaluación de modelos con validación cruzada estratificada\n",
    "\n",
    "Para evaluar el rendimiento de los modelos de clasificación sobre los datasets previamente balanceados, se utilizó validación cruzada estratificada de 5 particiones (Stratified K-Fold con *k=5*). Este método garantiza que en cada fold de entrenamiento y validación se preserve la proporción original de clases, lo cual es especialmente importante en tareas de clasificación multiclase con datasets balanceados artificialmente.\n",
    "\n",
    "Durante el proceso, cada modelo es entrenado y evaluado cinco veces, cada vez usando un subconjunto distinto como conjunto de prueba y el resto como conjunto de entrenamiento. Las métricas calculadas en cada iteración (F1-score macro, balanced accuracy, MCC y kappa de Cohen) se promedian para obtener un valor representativo y del rendimiento general del modelo sobre ese dataset aumentado.\n",
    "\n",
    "Este enfoque evita sobreajuste y proporciona una evaluación más confiable que una simple división train/test, permitiendo comparar de forma justa distintas configuraciones de sobremuestreo y modelos de clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5320c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 (1/76) Par: pcsmote_glass_D25_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (2/76) Par: pcsmote_glass_D25_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (3/76) Par: pcsmote_glass_D25_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (4/76) Par: pcsmote_glass_D25_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (5/76) Par: pcsmote_glass_D25_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (6/76) Par: pcsmote_glass_D25_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (7/76) Par: pcsmote_glass_D50_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (8/76) Par: pcsmote_glass_D50_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (9/76) Par: pcsmote_glass_D50_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (10/76) Par: pcsmote_glass_D50_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (11/76) Par: pcsmote_glass_D50_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (12/76) Par: pcsmote_glass_D50_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (13/76) Par: pcsmote_glass_D75_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (14/76) Par: pcsmote_glass_D75_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (15/76) Par: pcsmote_glass_D75_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (16/76) Par: pcsmote_glass_D75_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (17/76) Par: pcsmote_glass_D75_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (18/76) Par: pcsmote_glass_D75_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (19/76) Par: pcsmote_heart_D25_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (20/76) Par: pcsmote_heart_D25_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (21/76) Par: pcsmote_heart_D25_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (22/76) Par: pcsmote_heart_D25_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (23/76) Par: pcsmote_heart_D25_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (24/76) Par: pcsmote_heart_D25_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (25/76) Par: pcsmote_heart_D50_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (26/76) Par: pcsmote_heart_D50_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (27/76) Par: pcsmote_heart_D50_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (28/76) Par: pcsmote_heart_D50_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (29/76) Par: pcsmote_heart_D50_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (30/76) Par: pcsmote_heart_D50_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (31/76) Par: pcsmote_heart_D75_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (32/76) Par: pcsmote_heart_D75_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (33/76) Par: pcsmote_heart_D75_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (34/76) Par: pcsmote_heart_D75_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (35/76) Par: pcsmote_heart_D75_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (36/76) Par: pcsmote_heart_D75_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (37/76) Par: pcsmote_shuttle_D25_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '25', 'entropia'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '25', 'entropia'); se omite.\n",
      "⏭️  SVM omitido para Shuttle aumentado (regla de rendimiento).\n",
      "\n",
      "📂 (38/76) Par: pcsmote_shuttle_D25_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '25', 'proporcion'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '25', 'proporcion'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '25', 'proporcion'); se omite.\n",
      "\n",
      "📂 (39/76) Par: pcsmote_shuttle_D25_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '50', 'entropia'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '50', 'entropia'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '50', 'entropia'); se omite.\n",
      "\n",
      "📂 (40/76) Par: pcsmote_shuttle_D25_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '50', 'proporcion'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '50', 'proporcion'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '50', 'proporcion'); se omite.\n",
      "\n",
      "📂 (41/76) Par: pcsmote_shuttle_D25_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '75', 'entropia'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '75', 'entropia'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '75', 'entropia'); se omite.\n",
      "\n",
      "📂 (42/76) Par: pcsmote_shuttle_D25_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '75', 'proporcion'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '75', 'proporcion'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '25', '75', 'proporcion'); se omite.\n",
      "\n",
      "📂 (43/76) Par: pcsmote_shuttle_D50_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '25', 'entropia'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '25', 'entropia'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '25', 'entropia'); se omite.\n",
      "\n",
      "📂 (44/76) Par: pcsmote_shuttle_D50_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '25', 'proporcion'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '25', 'proporcion'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '25', 'proporcion'); se omite.\n",
      "\n",
      "📂 (45/76) Par: pcsmote_shuttle_D50_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '50', 'entropia'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '50', 'entropia'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '50', 'entropia'); se omite.\n",
      "\n",
      "📂 (46/76) Par: pcsmote_shuttle_D50_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '50', 'proporcion'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '50', 'proporcion'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '50', 'proporcion'); se omite.\n",
      "\n",
      "📂 (47/76) Par: pcsmote_shuttle_D50_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '75', 'entropia'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '75', 'entropia'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '75', 'entropia'); se omite.\n",
      "\n",
      "📂 (48/76) Par: pcsmote_shuttle_D50_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '75', 'proporcion'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '75', 'proporcion'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '50', '75', 'proporcion'); se omite.\n",
      "\n",
      "📂 (49/76) Par: pcsmote_shuttle_D75_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "⏭️  LogisticRegression: ya existe ('shuttle', 'aumentado', 'pcsmote', '75', '25', 'entropia'); se omite.\n",
      "⏭️  RandomForest: ya existe ('shuttle', 'aumentado', 'pcsmote', '75', '25', 'entropia'); se omite.\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '75', '25', 'entropia'); se omite.\n",
      "\n",
      "📂 (50/76) Par: pcsmote_shuttle_D75_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⏭️  SVM: ya existe ('shuttle', 'aumentado', 'pcsmote', '75', '25', 'proporcion'); se omite.\n",
      "\n",
      "📂 (51/76) Par: pcsmote_shuttle_D75_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⏭️  SVM omitido para Shuttle aumentado (regla de rendimiento).\n",
      "\n",
      "📂 (52/76) Par: pcsmote_shuttle_D75_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⏭️  SVM omitido para Shuttle aumentado (regla de rendimiento).\n",
      "\n",
      "📂 (53/76) Par: pcsmote_shuttle_D75_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⏭️  SVM omitido para Shuttle aumentado (regla de rendimiento).\n",
      "\n",
      "📂 (54/76) Par: pcsmote_shuttle_D75_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "⏭️  SVM omitido para Shuttle aumentado (regla de rendimiento).\n",
      "\n",
      "📂 (55/76) Par: pcsmote_wdbc_D25_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (56/76) Par: pcsmote_wdbc_D25_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (57/76) Par: pcsmote_wdbc_D25_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (58/76) Par: pcsmote_wdbc_D25_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (59/76) Par: pcsmote_wdbc_D25_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (60/76) Par: pcsmote_wdbc_D25_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (61/76) Par: pcsmote_wdbc_D50_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (62/76) Par: pcsmote_wdbc_D50_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (63/76) Par: pcsmote_wdbc_D50_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (64/76) Par: pcsmote_wdbc_D50_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (65/76) Par: pcsmote_wdbc_D50_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (66/76) Par: pcsmote_wdbc_D50_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (67/76) Par: pcsmote_wdbc_D75_R25_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (68/76) Par: pcsmote_wdbc_D75_R25_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (69/76) Par: pcsmote_wdbc_D75_R50_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (70/76) Par: pcsmote_wdbc_D75_R50_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (71/76) Par: pcsmote_wdbc_D75_R75_Pentropia_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (72/76) Par: pcsmote_wdbc_D75_R75_Pproporcion_train.csv  (tipo: aumentado)\n",
      "🔎 Técnica: pcsmote | Dataset: wdbc | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (73/76) Par: glass_train.csv  (tipo: base)\n",
      "🔎 Técnica: base | Dataset: glass | Densidad: NA | Riesgo: NA | Pureza: NA\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (74/76) Par: heart_train.csv  (tipo: base)\n",
      "🔎 Técnica: base | Dataset: heart | Densidad: NA | Riesgo: NA | Pureza: NA\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "📂 (75/76) Par: shuttle_train.csv  (tipo: base)\n",
      "🔎 Técnica: base | Dataset: shuttle | Densidad: NA | Riesgo: NA | Pureza: NA\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "📂 (76/76) Par: wdbc_train.csv  (tipo: base)\n",
      "🔎 Técnica: base | Dataset: wdbc | Densidad: NA | Riesgo: NA | Pureza: NA\n",
      "⚙️ Validando modelo con RandomizedSearchCV: LogisticRegression\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: RandomForest\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "⚙️ Validando modelo con RandomizedSearchCV: SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "📁 Resultados guardados: ../resultados\\resultados_SVM.csv\n",
      "📁 Resultados guardados: ../resultados\\resultados_LogisticRegression.csv\n",
      "📁 Resultados guardados: ../resultados\\resultados_RandomForest.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Modelos base + espacios (afinados)\n",
    "# -----------------------------\n",
    "modelos = {\n",
    "    \"SVM\": {\n",
    "        \"pipeline\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(random_state=42, probability=False, max_iter=5000, cache_size=400))\n",
    "        ]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__kernel': ['linear', 'rbf'],          # sin poly/sigmoid\n",
    "            'classifier__C': loguniform(1e-3, 1e2),\n",
    "            'classifier__gamma': loguniform(1e-4, 1e0),       # ignorado con 'linear'\n",
    "            'classifier__shrinking': [True, False],\n",
    "            'classifier__class_weight': [None, 'balanced']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"LogisticRegression\": {\n",
    "        \"pipeline\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(max_iter=5000, random_state=42))\n",
    "        ]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__solver': ['liblinear', 'saga'],\n",
    "            'classifier__penalty': ['l1', 'l2'],\n",
    "            'classifier__C': loguniform(1e-4, 1e2),\n",
    "            'classifier__fit_intercept': [True, False],\n",
    "            'classifier__class_weight': [None, 'balanced'],\n",
    "            'classifier__tol': loguniform(1e-5, 1e-3),\n",
    "            'classifier__dual': [False]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"RandomForest\": {\n",
    "        \"pipeline\": Pipeline([('classifier', RandomForestClassifier(\n",
    "            random_state=42, n_jobs=1, bootstrap=True, oob_score=False\n",
    "        ))]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__n_estimators': randint(200, 601),\n",
    "            'classifier__criterion': ['gini', 'entropy'],\n",
    "            'classifier__max_depth': [None, 10, 20, 40],\n",
    "            'classifier__min_samples_split': randint(2, 21),\n",
    "            'classifier__min_samples_leaf': randint(1, 11),\n",
    "            'classifier__max_features': ['sqrt', 'log2'],\n",
    "            'classifier__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "            'classifier__ccp_alpha': uniform(0.0, 0.01)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Orden: primero lo más rápido/estable\n",
    "orden_modelos = [\"LogisticRegression\", \"RandomForest\", \"SVM\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Rutas\n",
    "# -----------------------------\n",
    "ruta_aug  = \"../datasets/datasets_aumentados/\"\n",
    "ruta_base = \"../datasets/datasets_aumentados/base/\"\n",
    "dir_out   = \"../resultados\"\n",
    "os.makedirs(dir_out, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Listado de pares train/test\n",
    "# -----------------------------\n",
    "def listar_pares(ruta, tipo):\n",
    "    pares = []\n",
    "    if not os.path.isdir(ruta):\n",
    "        return pares\n",
    "    for f in os.listdir(ruta):\n",
    "        if not (f.endswith(\"_train.csv\") and os.path.isfile(os.path.join(ruta, f))):\n",
    "            continue\n",
    "        path_train = os.path.join(ruta, f)\n",
    "        path_test  = os.path.join(ruta, f.replace(\"_train.csv\", \"_test.csv\"))\n",
    "        if not os.path.isfile(path_test):\n",
    "            print(f\"⚠️ Falta el test para: {f} -> esperado: {os.path.basename(path_test)}\")\n",
    "            continue\n",
    "        pares.append({\n",
    "            \"tipo\": tipo,\n",
    "            \"nombre_train\": f,\n",
    "            \"path_train\": path_train,\n",
    "            \"path_test\": path_test\n",
    "        })\n",
    "    return pares\n",
    "\n",
    "pares = listar_pares(ruta_aug, \"aumentado\") + listar_pares(ruta_base, \"base\")\n",
    "pares = sorted(pares, key=lambda x: (x[\"tipo\"], x[\"nombre_train\"]))\n",
    "total_pares = len(pares)\n",
    "\n",
    "# -----------------------------\n",
    "# Métricas CV\n",
    "# -----------------------------\n",
    "scoring = {\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'balanced_accuracy': 'balanced_accuracy',\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'cohen_kappa': make_scorer(cohen_kappa_score)\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Resumible: claves ya calculadas\n",
    "# -----------------------------\n",
    "def cargar_claves_existentes():\n",
    "    done = {m: set() for m in modelos}\n",
    "    for m in modelos:\n",
    "        p = os.path.join(dir_out, f\"resultados_{m}.csv\")\n",
    "        if os.path.exists(p):\n",
    "            try:\n",
    "                df_prev = pd.read_csv(p)\n",
    "                for _, r in df_prev.iterrows():\n",
    "                    done[m].add((\n",
    "                        str(r.get('dataset')), str(r.get('tipo', '')),\n",
    "                        str(r.get('tecnica')), str(r.get('densidad')),\n",
    "                        str(r.get('riesgo')), str(r.get('pureza'))\n",
    "                    ))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return done\n",
    "\n",
    "ya_hechos = cargar_claves_existentes()\n",
    "resultados_por_modelo = {nombre: [] for nombre in modelos}\n",
    "\n",
    "# -----------------------------\n",
    "# Helper de carga (float32)\n",
    "# -----------------------------\n",
    "def cargar_xy(path_csv):\n",
    "    df = pd.read_csv(path_csv)\n",
    "    if \"target\" in df.columns:\n",
    "        X = df.drop(columns=[\"target\"]).to_numpy(dtype=np.float32, copy=False)\n",
    "        y = df[\"target\"].to_numpy()\n",
    "    else:\n",
    "        X = df.iloc[:, :-1].to_numpy(dtype=np.float32, copy=False)\n",
    "        y = df.iloc[:, -1].to_numpy()\n",
    "    return X, y\n",
    "\n",
    "# =============================\n",
    "# Loop principal\n",
    "# =============================\n",
    "for idx_par, item in enumerate(pares, start=1):\n",
    "    archivo_train = item[\"nombre_train\"]\n",
    "    ruta_train = item[\"path_train\"]; ruta_test = item[\"path_test\"]\n",
    "    tipo = item[\"tipo\"]\n",
    "\n",
    "    # Parseo nombre\n",
    "    nombre = archivo_train.replace(\".csv\", \"\")\n",
    "    partes = nombre.split(\"_\")\n",
    "    if tipo == \"aumentado\":\n",
    "        if len(partes) < 6:\n",
    "            print(f\"⚠️ Nombre inválido/incompleto (aumentado): {archivo_train}\")\n",
    "            continue\n",
    "        tecnica = partes[0]; nombre_dataset = partes[1]\n",
    "        densidad = partes[2][1:]; riesgo = partes[3][1:]; pureza = partes[4][1:]\n",
    "    else:\n",
    "        tecnica = \"base\"; nombre_dataset = nombre.replace(\"_train\", \"\")\n",
    "        densidad = riesgo = pureza = \"NA\"\n",
    "\n",
    "    print(f\"\\n📂 ({idx_par}/{total_pares}) Par: {archivo_train}  (tipo: {tipo})\")\n",
    "    print(f\"🔎 Técnica: {tecnica} | Dataset: {nombre_dataset} | Densidad: {densidad} | Riesgo: {riesgo} | Pureza: {pureza}\")\n",
    "\n",
    "    # Carga de datos\n",
    "    try:\n",
    "        X_train, y_train = cargar_xy(ruta_train)\n",
    "        X_test,  y_test  = cargar_xy(ruta_test)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al leer train/test ({archivo_train}): {e}\")\n",
    "        continue\n",
    "\n",
    "    n_samples, n_features = X_train.shape\n",
    "    es_grande = (n_samples >= 10000) or (nombre_dataset.lower() == \"shuttle\")\n",
    "    es_shuttle_aum = (nombre_dataset.lower() == \"shuttle\") and (tipo == \"aumentado\")\n",
    "\n",
    "    # CV / iteraciones / paralelismo\n",
    "    cv_base   = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_grande = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_shuttle= StratifiedKFold(n_splits=2, shuffle=True, random_state=42)  # aún más liviano\n",
    "\n",
    "    if es_shuttle_aum:\n",
    "        cv_actual = cv_shuttle\n",
    "        n_iter_default = 2\n",
    "    else:\n",
    "        cv_actual = (cv_grande if es_grande else cv_base)\n",
    "        n_iter_default = (3 if (es_grande and tipo == \"aumentado\") else (5 if es_grande else 10))\n",
    "\n",
    "    cpu = os.cpu_count() or 4\n",
    "    n_jobs_default = 1 if es_grande else max(1, min(4, cpu // 2))\n",
    "    pre_dispatch_v = \"n_jobs\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Por modelo (ordenado)\n",
    "    # -------------------------\n",
    "    for nombre_modelo in orden_modelos:\n",
    "        info = modelos[nombre_modelo]\n",
    "        key = (nombre_dataset, tipo, tecnica, str(densidad), str(riesgo), str(pureza))\n",
    "        if key in ya_hechos[nombre_modelo]:\n",
    "            print(f\"⏭️  {nombre_modelo}: ya existe {key}; se omite.\")\n",
    "            continue\n",
    "\n",
    "        # REGLA ESPECIAL: Shuttle aumentado → NO SVM\n",
    "        if es_shuttle_aum and nombre_modelo == \"SVM\":\n",
    "            print(\"⏭️  SVM omitido para Shuttle aumentado (regla de rendimiento).\")\n",
    "            continue\n",
    "\n",
    "        print(f\"⚙️ Validando modelo con RandomizedSearchCV: {nombre_modelo}\")\n",
    "\n",
    "        # Config local + espacio adaptado\n",
    "        if nombre_modelo == \"SVM\":\n",
    "            pipeline_local = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', SVC(random_state=42, probability=False, max_iter=5000, cache_size=400))\n",
    "            ])\n",
    "            params_local = {\n",
    "                'classifier__kernel': ['linear'] if es_grande else ['linear', 'rbf'],\n",
    "                'classifier__C': (uniform(0.1, 10.0) if es_grande else loguniform(1e-3, 1e2)),\n",
    "                'classifier__gamma': (['scale'] if es_grande else loguniform(1e-4, 1e0)),\n",
    "                'classifier__shrinking': [True, False],\n",
    "                'classifier__class_weight': [None, 'balanced']\n",
    "            }\n",
    "\n",
    "        elif nombre_modelo == \"LogisticRegression\":\n",
    "            pipeline_local = info['pipeline']\n",
    "            if es_shuttle_aum:\n",
    "                # Solo 'saga' + L2 (más estable/rápido en n grande multiclass)\n",
    "                params_local = {\n",
    "                    'classifier__solver': ['saga'],\n",
    "                    'classifier__penalty': ['l2'],\n",
    "                    'classifier__C': loguniform(1e-3, 1e1),\n",
    "                    'classifier__fit_intercept': [True],\n",
    "                    'classifier__class_weight': ['balanced'],\n",
    "                    'classifier__tol': loguniform(1e-4, 1e-2),\n",
    "                    'classifier__dual': [False]\n",
    "                }\n",
    "            else:\n",
    "                params_local = info['param_distributions']\n",
    "\n",
    "        else:  # RandomForest\n",
    "            pipeline_local = info['pipeline']  # n_jobs=1\n",
    "            if es_shuttle_aum:\n",
    "                params_local = {\n",
    "                    'classifier__n_estimators': randint(150, 351),   # 150-350\n",
    "                    'classifier__criterion': ['gini'],\n",
    "                    'classifier__max_depth': [None, 10, 20],\n",
    "                    'classifier__min_samples_split': randint(2, 11),\n",
    "                    'classifier__min_samples_leaf': randint(1, 6),\n",
    "                    'classifier__max_features': ['sqrt'],\n",
    "                    'classifier__class_weight': ['balanced_subsample'],\n",
    "                    'classifier__ccp_alpha': uniform(0.0, 0.005),\n",
    "                    'classifier__max_samples': uniform(0.5, 0.45)     # 0.5–0.95 del bag → acelera bastante\n",
    "                }\n",
    "            else:\n",
    "                # espacio base + opción de max_samples moderada\n",
    "                base = info['param_distributions'].copy()\n",
    "                base['classifier__max_samples'] = uniform(0.6, 0.35)  # 0.6–0.95\n",
    "                params_local = base\n",
    "\n",
    "        n_iter_actual = n_iter_default\n",
    "        n_jobs_actual = n_jobs_default\n",
    "\n",
    "        # Búsqueda\n",
    "        try:\n",
    "            t0 = time.perf_counter()\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=pipeline_local,\n",
    "                param_distributions=params_local,\n",
    "                n_iter=n_iter_actual,\n",
    "                cv=cv_actual,\n",
    "                scoring=scoring,\n",
    "                refit='f1_macro',\n",
    "                random_state=42,\n",
    "                n_jobs=n_jobs_actual,\n",
    "                pre_dispatch=pre_dispatch_v,   # evita colas gigantes\n",
    "                verbose=1,\n",
    "                return_train_score=False,\n",
    "                error_score='raise'\n",
    "            )\n",
    "            search.fit(X_train, y_train)\n",
    "            elapsed = round(time.perf_counter() - t0, 3)\n",
    "\n",
    "            # CV (mejor índice)\n",
    "            bi = search.best_index_\n",
    "            cv_f1    = float(search.cv_results_['mean_test_f1_macro'][bi])\n",
    "            cv_bacc  = float(search.cv_results_['mean_test_balanced_accuracy'][bi])\n",
    "            cv_mcc   = float(search.cv_results_['mean_test_mcc'][bi])\n",
    "            cv_kappa = float(search.cv_results_['mean_test_cohen_kappa'][bi])\n",
    "\n",
    "            # Test\n",
    "            best_est = search.best_estimator_\n",
    "            y_pred   = best_est.predict(X_test)\n",
    "            test_f1   = float(f1_score(y_test, y_pred, average='macro'))\n",
    "            test_bacc = float(balanced_accuracy_score(y_test, y_pred))\n",
    "            test_mcc  = float(matthews_corrcoef(y_test, y_pred))\n",
    "            test_kappa= float(cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "            # Registrar\n",
    "            resultados_por_modelo[nombre_modelo].append({\n",
    "                'dataset': nombre_dataset, 'tipo': tipo, 'tecnica': tecnica,\n",
    "                'densidad': densidad, 'riesgo': riesgo, 'pureza': pureza,\n",
    "                'n_train': int(n_samples), 'n_test': int(X_test.shape[0]),\n",
    "                'n_features': int(n_features), 'es_grande': bool(es_grande),\n",
    "                'cv_splits': cv_actual.get_n_splits(), 'n_iter': n_iter_actual,\n",
    "                'modelo': nombre_modelo, 'mejor_configuracion': str(search.best_params_),\n",
    "                'cv_f1_macro': cv_f1, 'cv_balanced_accuracy': cv_bacc,\n",
    "                'cv_mcc': cv_mcc, 'cv_cohen_kappa': cv_kappa,\n",
    "                'test_f1_macro': test_f1, 'test_balanced_accuracy': test_bacc,\n",
    "                'test_mcc': test_mcc, 'test_cohen_kappa': test_kappa,\n",
    "                'search_time_sec': elapsed, 'n_jobs_search': n_jobs_actual\n",
    "            })\n",
    "\n",
    "            # Volcado incremental y marca como hecho\n",
    "            out_path = os.path.join(dir_out, f\"resultados_{nombre_modelo}.csv\")\n",
    "            pd.DataFrame(resultados_por_modelo[nombre_modelo]).to_csv(out_path, index=False)\n",
    "            ya_hechos[nombre_modelo].add(key)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error al validar {nombre_modelo} en {archivo_train}: {e}\")\n",
    "\n",
    "        # Limpieza de memoria\n",
    "        gc.collect()\n",
    "\n",
    "# -----------------------------\n",
    "# Persistencia final por modelo\n",
    "# -----------------------------\n",
    "for nombre_modelo, lista in resultados_por_modelo.items():\n",
    "    out_path = os.path.join(dir_out, f\"resultados_{nombre_modelo}.csv\")\n",
    "    pd.DataFrame(lista).to_csv(out_path, index=False)\n",
    "    print(f\"📁 Resultados guardados: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
