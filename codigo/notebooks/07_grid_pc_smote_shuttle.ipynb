{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27267283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "sys.path.append(\"../datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee7abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cargar_dataset import cargar_dataset\n",
    "from config_datasets import config_datasets\n",
    "from evaluacion import evaluar_sampler_holdout\n",
    "from custom_samplers import PCSMOTEWrapper\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    f1_score, balanced_accuracy_score,\n",
    "    matthews_corrcoef, cohen_kappa_score\n",
    ")\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pc_smote import PCSMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, matthews_corrcoef, cohen_kappa_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d665899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # ğŸ‘ˆ agregado\n",
    "\n",
    "def aumentar_dataset_pcsmote_y_guardar(nombre_dataset, config, percentil_densidad, percentil_riesgo, criterio_pureza, test_size=0.2):\n",
    "    print(f\"ğŸ“‚ Cargando dataset: {nombre_dataset}\")\n",
    "\n",
    "    try:\n",
    "        # 1) Cargar dataset original\n",
    "        X, y, clases = cargar_dataset(\n",
    "            path=config[\"path\"],\n",
    "            clase_minoria=config.get(\"clase_minoria\"),\n",
    "            col_features=config.get(\"col_features\"),\n",
    "            col_target=config.get(\"col_target\"),\n",
    "            sep=config.get(\"sep\", \",\"),\n",
    "            header=config.get(\"header\", None),\n",
    "            binarizar=False,\n",
    "            tipo=config.get(\"tipo\", \"tabular\")\n",
    "        )\n",
    "\n",
    "        # 2) Codificar etiquetas si son strings\n",
    "        if y.dtype == object or isinstance(y[0], str):\n",
    "            y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "        # 3) Si es un dataset de imÃ¡genes, convertir a vector plano\n",
    "        if config.get(\"tipo\") == \"imagen\":\n",
    "            X = X.reshape((X.shape[0], -1)).astype(np.float32)\n",
    "\n",
    "        # 4) Dividir en train/test (antes de sobremuestrear)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # 5) Escalar ambos usando estadÃ­sticas del train\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # 6) Aplicar PCSMOTE sobre el set de entrenamiento escalado\n",
    "        print(f\"ğŸ§¬ Aplicando PCSMOTE | Densidad: {percentil_densidad} | Riesgo: {percentil_riesgo} | Pureza: {criterio_pureza}\")\n",
    "        sampler = PCSMOTE(\n",
    "            random_state=42,\n",
    "            percentil_densidad=percentil_densidad,\n",
    "            percentil_dist=percentil_riesgo,\n",
    "            criterio_pureza=criterio_pureza,\n",
    "            modo_espacial='3d'\n",
    "        )\n",
    "        sampler.nombre_dataset = nombre_dataset\n",
    "\n",
    "        if hasattr(sampler, \"fit_resample_multiclass\"):\n",
    "            X_train_res, y_train_res = sampler.fit_resample_multiclass(X_train, y_train)\n",
    "        else:\n",
    "            X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # 7) Guardar datasets: train aumentado y test escalado\n",
    "        print(f\"ğŸ’¾ Guardando datasets aumentados...\")\n",
    "\n",
    "        ruta_salida = f\"../datasets/datasets_aumentados/\"\n",
    "        os.makedirs(ruta_salida, exist_ok=True)\n",
    "\n",
    "        nombre_base = f\"pcsmote_{nombre_dataset}_D{percentil_densidad}_R{percentil_riesgo}_P{criterio_pureza}\"\n",
    "        path_train = os.path.join(ruta_salida, f\"{nombre_base}_train.csv\")\n",
    "        path_test = os.path.join(ruta_salida, f\"{nombre_base}_test.csv\")\n",
    "\n",
    "        # Guardar train aumentado\n",
    "        df_train = pd.DataFrame(X_train_res)\n",
    "        df_train[\"target\"] = y_train_res\n",
    "        df_train.to_csv(path_train, index=False)\n",
    "\n",
    "        # Guardar test escalado (sin sobremuestrear)\n",
    "        df_test = pd.DataFrame(X_test)\n",
    "        df_test[\"target\"] = y_test\n",
    "        df_test.to_csv(path_test, index=False)\n",
    "\n",
    "        print(f\"âœ… Datasets guardados:\\n- Train aumentado: {path_train}\\n- Test escalado: {path_test}\")\n",
    "        return path_train, path_test, sampler\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error al aumentar dataset {nombre_dataset}: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98760b9d",
   "metadata": {},
   "source": [
    "### ğŸ§¬ Aumento de Datasets mediante TÃ©cnicas de Sobremuestreo\n",
    "\n",
    "En esta etapa se genera una versiÃ³n balanceada de cada dataset original mediante la aplicaciÃ³n de tÃ©cnicas de sobremuestreo, con el objetivo de mitigar el desbalance de clases antes del entrenamiento de los modelos.\n",
    "\n",
    "Actualmente, se emplea la tÃ©cnica:\n",
    "\n",
    "- `PCSMOTE` (Percentile-Controlled SMOTE), que permite controlar la generaciÃ³n de muestras sintÃ©ticas en funciÃ³n de percentiles de densidad, riesgo y pureza.\n",
    "\n",
    "Para cada dataset, se exploran combinaciones especÃ­ficas de parÃ¡metros segÃºn la tÃ©cnica utilizada. Los datasets resultantes se almacenan en el directorio `datasets/datasets_aumentados/`, utilizando nombres de archivo que reflejan la configuraciÃ³n empleada (por ejemplo: `pcsmote_nombre_D25_R50_Pentropia_train.csv`).\n",
    "\n",
    "> âš ï¸ Esta fase no incluye entrenamiento ni validaciÃ³n de modelos. Su Ãºnico propÃ³sito es generar conjuntos de datos aumentados a partir del conjunto de entrenamiento. La particiÃ³n `train/test` se realiza previamente, y **solo la parte de entrenamiento es sometida a sobremuestreo**. El conjunto de prueba permanece sin modificar para garantizar una evaluaciÃ³n imparcial posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f74ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Dataset: shuttle\n",
      "#01 â• Aumentando con D=25 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R25_Pentropia.csv\n",
      "#02 â• Aumentando con D=25 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R25_Pproporcion.csv\n",
      "#03 â• Aumentando con D=25 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R50_Pentropia.csv\n",
      "#04 â• Aumentando con D=25 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R50_Pproporcion.csv\n",
      "#05 â• Aumentando con D=25 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R75_Pentropia.csv\n",
      "#06 â• Aumentando con D=25 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R75_Pproporcion.csv\n",
      "#07 â• Aumentando con D=50 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R25_Pentropia.csv\n",
      "#08 â• Aumentando con D=50 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R25_Pproporcion.csv\n",
      "#09 â• Aumentando con D=50 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R50_Pentropia.csv\n",
      "#10 â• Aumentando con D=50 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R50_Pproporcion.csv\n",
      "#11 â• Aumentando con D=50 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R75_Pentropia.csv\n",
      "#12 â• Aumentando con D=50 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R75_Pproporcion.csv\n",
      "#13 â• Aumentando con D=75 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R25_Pentropia.csv\n",
      "#14 â• Aumentando con D=75 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R25_Pproporcion.csv\n",
      "#15 â• Aumentando con D=75 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R50_Pentropia.csv\n",
      "#16 â• Aumentando con D=75 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R50_Pproporcion.csv\n",
      "#17 â• Aumentando con D=75 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R75_Pentropia.csv\n",
      "#18 â• Aumentando con D=75 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: shuttle\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R75_Pproporcion.csv\n",
      "\n",
      "ğŸ“ Dataset: wdbc\n",
      "#01 â• Aumentando con D=25 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R25_Pentropia.csv\n",
      "#02 â• Aumentando con D=25 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R25_Pproporcion.csv\n",
      "#03 â• Aumentando con D=25 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R50_Pentropia.csv\n",
      "#04 â• Aumentando con D=25 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R50_Pproporcion.csv\n",
      "#05 â• Aumentando con D=25 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R75_Pentropia.csv\n",
      "#06 â• Aumentando con D=25 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R75_Pproporcion.csv\n",
      "#07 â• Aumentando con D=50 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R25_Pentropia.csv\n",
      "#08 â• Aumentando con D=50 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R25_Pproporcion.csv\n",
      "#09 â• Aumentando con D=50 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R50_Pentropia.csv\n",
      "#10 â• Aumentando con D=50 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R50_Pproporcion.csv\n",
      "#11 â• Aumentando con D=50 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R75_Pentropia.csv\n",
      "#12 â• Aumentando con D=50 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R75_Pproporcion.csv\n",
      "#13 â• Aumentando con D=75 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R25_Pentropia.csv\n",
      "#14 â• Aumentando con D=75 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R25_Pproporcion.csv\n",
      "#15 â• Aumentando con D=75 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R50_Pentropia.csv\n",
      "#16 â• Aumentando con D=75 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R50_Pproporcion.csv\n",
      "#17 â• Aumentando con D=75 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R75_Pentropia.csv\n",
      "#18 â• Aumentando con D=75 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: wdbc\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R75_Pproporcion.csv\n",
      "\n",
      "ğŸ“ Dataset: glass\n",
      "#01 â• Aumentando con D=25 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R25_Pentropia.csv\n",
      "#02 â• Aumentando con D=25 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R25_Pproporcion.csv\n",
      "#03 â• Aumentando con D=25 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R50_Pentropia.csv\n",
      "#04 â• Aumentando con D=25 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R50_Pproporcion.csv\n",
      "#05 â• Aumentando con D=25 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R75_Pentropia.csv\n",
      "#06 â• Aumentando con D=25 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R75_Pproporcion.csv\n",
      "#07 â• Aumentando con D=50 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R25_Pentropia.csv\n",
      "#08 â• Aumentando con D=50 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R25_Pproporcion.csv\n",
      "#09 â• Aumentando con D=50 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R50_Pentropia.csv\n",
      "#10 â• Aumentando con D=50 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R50_Pproporcion.csv\n",
      "#11 â• Aumentando con D=50 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R75_Pentropia.csv\n",
      "#12 â• Aumentando con D=50 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R75_Pproporcion.csv\n",
      "#13 â• Aumentando con D=75 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R25_Pentropia.csv\n",
      "#14 â• Aumentando con D=75 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R25_Pproporcion.csv\n",
      "#15 â• Aumentando con D=75 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R50_Pentropia.csv\n",
      "#16 â• Aumentando con D=75 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R50_Pproporcion.csv\n",
      "#17 â• Aumentando con D=75 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R75_Pentropia.csv\n",
      "#18 â• Aumentando con D=75 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: glass\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R75_Pproporcion.csv\n",
      "\n",
      "ğŸ“ Dataset: heart\n",
      "#01 â• Aumentando con D=25 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R25_Pentropia.csv\n",
      "#02 â• Aumentando con D=25 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R25_Pproporcion.csv\n",
      "#03 â• Aumentando con D=25 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R50_Pentropia.csv\n",
      "#04 â• Aumentando con D=25 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R50_Pproporcion.csv\n",
      "#05 â• Aumentando con D=25 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R75_Pentropia.csv\n",
      "#06 â• Aumentando con D=25 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R75_Pproporcion.csv\n",
      "#07 â• Aumentando con D=50 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R25_Pentropia.csv\n",
      "#08 â• Aumentando con D=50 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R25_Pproporcion.csv\n",
      "#09 â• Aumentando con D=50 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R50_Pentropia.csv\n",
      "#10 â• Aumentando con D=50 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R50_Pproporcion.csv\n",
      "#11 â• Aumentando con D=50 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R75_Pentropia.csv\n",
      "#12 â• Aumentando con D=50 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R75_Pproporcion.csv\n",
      "#13 â• Aumentando con D=75 | R=25 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R25_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R25_Pentropia.csv\n",
      "#14 â• Aumentando con D=75 | R=25 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R25_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R25_Pproporcion.csv\n",
      "#15 â• Aumentando con D=75 | R=50 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R50_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R50_Pentropia.csv\n",
      "#16 â• Aumentando con D=75 | R=50 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R50_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R50_Pproporcion.csv\n",
      "#17 â• Aumentando con D=75 | R=75 | P=entropia\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pentropia_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pentropia_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R75_Pentropia.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R75_Pentropia.csv\n",
      "#18 â• Aumentando con D=75 | R=75 | P=proporcion\n",
      "ğŸ“‚ Cargando dataset: heart\n",
      "âš ï¸ Advertencia: columnas no numÃ©ricas detectadas: [11, 12]\n",
      "ğŸ§¬ Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "ğŸ’¾ Guardando datasets aumentados...\n",
      "âœ… Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pproporcion_test.csv\n",
      "âœ… Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pproporcion_test.csv\n",
      "ğŸ“ Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R75_Pproporcion.csv\n",
      "ğŸ“„ Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R75_Pproporcion.csv\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "\n",
    "percentiles_densidad = [25, 50, 75]\n",
    "percentiles_riesgo = [25, 50, 75]\n",
    "criterios_pureza = [\"entropia\", \"proporcion\"]\n",
    "\n",
    "# Generar todas las combinaciones del grid\n",
    "combinaciones = list(product(percentiles_densidad, percentiles_riesgo, criterios_pureza))\n",
    "\n",
    "# Asegurarse de que el directorio de logs exista\n",
    "os.makedirs(\"../logs/\", exist_ok=True)\n",
    "\n",
    "# Recorrer todos los datasets\n",
    "for nombre_dataset, config in config_datasets.items():\n",
    "    if nombre_dataset == \"eurosat\":\n",
    "        continue  # opcional: saltear imagenes si no estÃ¡s trabajando con reshape 3D aÃºn\n",
    "\n",
    "    print(f\"\\nğŸ“ Dataset: {nombre_dataset}\")\n",
    "\n",
    "    for idx, (pdens, priesgo, criterio) in enumerate(combinaciones, start=1):\n",
    "        print(f\"#{idx:02d} â• Aumentando con D={pdens} | R={priesgo} | P={criterio}\")\n",
    "\n",
    "        # Ejecutar aumento y guardar resultados\n",
    "        path_train, path_test, sampler = aumentar_dataset_pcsmote_y_guardar(\n",
    "            nombre_dataset=nombre_dataset,\n",
    "            config=config,\n",
    "            percentil_densidad=pdens,\n",
    "            percentil_riesgo=priesgo,\n",
    "            criterio_pureza=criterio\n",
    "        )\n",
    "\n",
    "        if path_train and sampler:\n",
    "            print(f\"âœ… Guardado exitoso:\\n - Train: {path_train}\\n - Test: {path_test}\")\n",
    "\n",
    "            # Guardar log por combinaciÃ³n\n",
    "            log_path = f\"../datasets/datasets_aumentados/logs/log_pcsmote_{nombre_dataset}_D{pdens}_R{priesgo}_P{criterio}.csv\"\n",
    "            sampler.exportar_log_csv(log_path)\n",
    "            print(f\"ğŸ“„ Log exportado: {log_path}\")\n",
    "        else:\n",
    "            print(\"âŒ FallÃ³ la generaciÃ³n.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc87fa1",
   "metadata": {},
   "source": [
    "### EvaluaciÃ³n de modelos con validaciÃ³n cruzada estratificada\n",
    "\n",
    "Para evaluar el rendimiento de los modelos de clasificaciÃ³n sobre los datasets previamente balanceados, se utilizÃ³ validaciÃ³n cruzada estratificada de 5 particiones (Stratified K-Fold con *k=5*). Este mÃ©todo garantiza que en cada fold de entrenamiento y validaciÃ³n se preserve la proporciÃ³n original de clases, lo cual es especialmente importante en tareas de clasificaciÃ³n multiclase con datasets balanceados artificialmente.\n",
    "\n",
    "Durante el proceso, cada modelo es entrenado y evaluado cinco veces, cada vez usando un subconjunto distinto como conjunto de prueba y el resto como conjunto de entrenamiento. Las mÃ©tricas calculadas en cada iteraciÃ³n (F1-score macro, balanced accuracy, MCC y kappa de Cohen) se promedian para obtener un valor representativo y del rendimiento general del modelo sobre ese dataset aumentado.\n",
    "\n",
    "Este enfoque evita sobreajuste y proporciona una evaluaciÃ³n mÃ¡s confiable que una simple divisiÃ³n train/test, permitiendo comparar de forma justa distintas configuraciones de sobremuestreo y modelos de clasificaciÃ³n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5320c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D25_R25_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D25_R25_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D25_R50_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D25_R50_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D25_R75_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D25_R75_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D50_R25_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D50_R25_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D50_R50_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D50_R50_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D50_R75_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D50_R75_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D75_R25_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D75_R25_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D75_R50_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D75_R50_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D75_R75_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_glass_D75_R75_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D25_R25_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D25_R25_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D25_R50_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D25_R50_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D25_R75_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D25_R75_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D50_R25_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D50_R25_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D50_R50_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D50_R50_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D50_R75_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D50_R75_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D75_R25_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D75_R25_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D75_R50_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D75_R50_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D75_R75_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_heart_D75_R75_Pproporcion_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "ğŸ“‚ Dataset aumentado: pcsmote_shuttle_D25_R25_Pentropia_train.csv\n",
      "ğŸ” TÃ©cnica: pcsmote | Dataset: shuttle | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 98\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     89\u001b[0m         estimator\u001b[38;5;241m=\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     90\u001b[0m         param_distributions\u001b[38;5;241m=\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_distributions\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     97\u001b[0m     )\n\u001b[1;32m---> 98\u001b[0m     \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     df_mean \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score_macro\u001b[39m\u001b[38;5;124m'\u001b[39m: search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_f1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m][search\u001b[38;5;241m.\u001b[39mbest_index_],\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_balanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][search\u001b[38;5;241m.\u001b[39mbest_index_],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmejor_configuracion\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m    112\u001b[0m     }\n\u001b[0;32m    114\u001b[0m     resultados_por_modelo[nombre_modelo]\u001b[38;5;241m.\u001b[39mappend(df_mean)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Modelos y sus espacios de hiperparÃ¡metros\n",
    "modelos = {\n",
    "    \"SVM\": {\n",
    "        \"pipeline\": Pipeline([\n",
    "            ('classifier', SVC(random_state=42))\n",
    "        ]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__C': uniform(0.1, 10),\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__gamma': ['scale', 'auto']\n",
    "        }\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"pipeline\": Pipeline([\n",
    "            ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "        ]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__C': uniform(0.1, 10),\n",
    "            'classifier__penalty': ['l2'],\n",
    "            'classifier__solver': ['lbfgs']\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"pipeline\": Pipeline([\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ruta de datasets aumentados\n",
    "ruta = \"../datasets/datasets_aumentados/\"\n",
    "archivos = [f for f in os.listdir(ruta) if f.endswith(\"_train.csv\")]\n",
    "\n",
    "# MÃ©tricas personalizadas\n",
    "scoring = {\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'balanced_accuracy': 'balanced_accuracy',\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'cohen_kappa': make_scorer(cohen_kappa_score)\n",
    "}\n",
    "\n",
    "# Resultados acumulados\n",
    "resultados_por_modelo = {nombre: [] for nombre in modelos}\n",
    "\n",
    "# EvaluaciÃ³n por archivo CSV\n",
    "for archivo in archivos:\n",
    "    partes = archivo.replace(\".csv\", \"\").split(\"_\")\n",
    "    if len(partes) < 5:\n",
    "        print(f\"âš ï¸ Nombre de archivo invÃ¡lido o incompleto: {archivo}\")\n",
    "        continue\n",
    "\n",
    "    tecnica = partes[0]\n",
    "    nombre_dataset = partes[1]\n",
    "    densidad = partes[2][1:]\n",
    "    riesgo = partes[3][1:]\n",
    "    pureza = partes[4][1:]\n",
    "\n",
    "    print(f\"\\nğŸ“‚ Dataset aumentado: {archivo}\")\n",
    "    print(f\"ğŸ” TÃ©cnica: {tecnica} | Dataset: {nombre_dataset} | Densidad: {densidad} | Riesgo: {riesgo} | Pureza: {pureza}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(ruta, archivo))\n",
    "        X = df.drop(columns=[\"target\"]).values\n",
    "        y = df[\"target\"].values\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        for nombre_modelo, info in modelos.items():\n",
    "            print(f\"âš™ï¸ Validando modelo con Pipeline y RandomizedSearchCV: {nombre_modelo}\")\n",
    "\n",
    "            try:\n",
    "                search = RandomizedSearchCV(\n",
    "                    estimator=info['pipeline'],\n",
    "                    param_distributions=info['param_distributions'],\n",
    "                    n_iter=10,\n",
    "                    cv=cv,\n",
    "                    scoring=scoring,\n",
    "                    refit='f1_macro',\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                search.fit(X, y)\n",
    "\n",
    "                df_mean = {\n",
    "                    'f1_score_macro': search.cv_results_['mean_test_f1_macro'][search.best_index_],\n",
    "                    'balanced_accuracy': search.cv_results_['mean_test_balanced_accuracy'][search.best_index_],\n",
    "                    'mcc': search.cv_results_['mean_test_mcc'][search.best_index_],\n",
    "                    'cohen_kappa': search.cv_results_['mean_test_cohen_kappa'][search.best_index_],\n",
    "                    'dataset': nombre_dataset,\n",
    "                    'tecnica': tecnica,\n",
    "                    'modelo': nombre_modelo,\n",
    "                    'densidad': densidad,\n",
    "                    'riesgo': riesgo,\n",
    "                    'pureza': pureza,\n",
    "                    'mejor_configuracion': str(search.best_params_)\n",
    "                }\n",
    "\n",
    "                resultados_por_modelo[nombre_modelo].append(df_mean)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error al validar modelo {nombre_modelo} en {archivo}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error al procesar archivo {archivo}: {e}\")\n",
    "\n",
    "# Guardar resultados\n",
    "os.makedirs(\"../resultados\", exist_ok=True)\n",
    "for nombre_modelo, lista_resultados in resultados_por_modelo.items():\n",
    "    df_final = pd.DataFrame(lista_resultados)\n",
    "    output_path = f\"../resultados/resultados_{nombre_modelo}.csv\"\n",
    "    df_final.to_csv(output_path, index=False)\n",
    "    print(f\"ğŸ“ Resultados guardados: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb30cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_otra_tecnica_grid(nombre_dataset, config, tecnica, modelo_clasificador, nombre_modelo, nombre_tec):\n",
    "    print(f\"ğŸ“‚ Cargando dataset: {nombre_dataset}\")\n",
    "    X, y, _ = cargar_dataset(\n",
    "        path=config[\"path\"],\n",
    "        clase_minoria=config.get(\"clase_minoria\"),\n",
    "        col_features=config.get(\"col_features\"),\n",
    "        col_target=config.get(\"col_target\"),\n",
    "        sep=config.get(\"sep\", \",\"),\n",
    "        header=config.get(\"header\", None),\n",
    "        binarizar=False,\n",
    "        tipo=config.get(\"tipo\", \"tabular\")\n",
    "    )\n",
    "\n",
    "    if y.dtype == object or isinstance(y[0], str):\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    if config.get(\"tipo\") == \"imagen\":\n",
    "        X = X.reshape((X.shape[0], -1)).astype(np.float32)\n",
    "\n",
    "    clases_minor = config.get(\"clases_minor\", [])\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    metricas_fold = []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"ğŸ” Fold {fold_idx + 1}/5\")\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        pca = PCA(n_components=min(X_train.shape[1], 100))\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        try:\n",
    "            if tecnica:\n",
    "                X_res, y_res = tecnica.fit_resample(X_train_pca, y_train)\n",
    "            else:\n",
    "                X_res, y_res = X_train_pca, y_train\n",
    "\n",
    "            modelo_escalado = get_modelo_escalado_si_es_necesario(modelo_clasificador, nombre_modelo)\n",
    "            modelo_escalado.fit(X_res, y_res)\n",
    "            y_pred = modelo_escalado.predict(X_test_pca)\n",
    "\n",
    "            f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "            balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "            kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "            f1_minor = None\n",
    "            if clases_minor:\n",
    "                mask = np.isin(y_test, clases_minor)\n",
    "                if np.any(mask):\n",
    "                    f1_minor = f1_score(y_test[mask], y_pred[mask], average='macro')\n",
    "\n",
    "            metricas_fold.append({\n",
    "                'f1_score_macro': f1_macro,\n",
    "                'f1_score_minor': f1_minor,\n",
    "                'balanced_accuracy': balanced_acc,\n",
    "                'mcc': mcc,\n",
    "                'cohen_kappa': kappa\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error en fold {fold_idx + 1}: {e}\")\n",
    "            metricas_fold.append({\n",
    "                'f1_score_macro': None,\n",
    "                'f1_score_minor': None,\n",
    "                'balanced_accuracy': None,\n",
    "                'mcc': None,\n",
    "                'cohen_kappa': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "    df_metricas = pd.DataFrame(metricas_fold)\n",
    "    df_mean = df_metricas.dropna().mean(numeric_only=True).to_dict()\n",
    "    df_mean.update({\n",
    "        'dataset': nombre_dataset,\n",
    "        'modelo': nombre_modelo,\n",
    "        'tecnica': nombre_tec\n",
    "    })\n",
    "\n",
    "    df_final = pd.DataFrame([df_mean])\n",
    "    df_final.to_csv(f\"../resultados/{nombre_tec}_grid_{nombre_dataset}_{nombre_modelo}.csv\", index=False)\n",
    "    print(f\"ğŸ“ Resultados guardados en: ../resultados/{nombre_tec}_grid_{nombre_dataset}_{nombre_modelo}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluar_pcsmote_grid_search(nombre_dataset, config, percentiles_densidad, percentiles_riesgo, criterios_pureza, modelo_clasificador, nombre_modelo):\n",
    "    print(f\"ğŸ“‚ Cargando dataset: {nombre_dataset}\")\n",
    "\n",
    "    # 1) Cargar dataset segÃºn los parÃ¡metros recibidos (ruta, columnas, tipo, etc.)\n",
    "    X, y, _ = cargar_dataset(\n",
    "        path=config[\"path\"],\n",
    "        clase_minoria=config.get(\"clase_minoria\"),\n",
    "        col_features=config.get(\"col_features\"),\n",
    "        col_target=config.get(\"col_target\"),\n",
    "        sep=config.get(\"sep\", \",\"),\n",
    "        header=config.get(\"header\", None),\n",
    "        binarizar=False,\n",
    "        tipo=config.get(\"tipo\", \"tabular\")\n",
    "    )\n",
    "\n",
    "    # 2) Codificar etiquetas si son strings u objetos\n",
    "    if y.dtype == object or isinstance(y[0], str):  \n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    # 3) Si es un dataset de imÃ¡genes, aplastar (reshape) cada imagen a vector 1D\n",
    "    # Esto convierte (N, H, W, C) en (N, H*W*C) para trabajar como tabular\n",
    "    if config.get(\"tipo\") == \"imagen\":\n",
    "        X = X.reshape((X.shape[0], -1)).astype(np.float32)\n",
    "\n",
    "    # 4) Obtener clases minoritarias si estÃ¡n definidas\n",
    "    clases_minor = config.get(\"clases_minor\", [])\n",
    "    resultados = []\n",
    "\n",
    "    # 5) Dividir en train/test con estratificaciÃ³n, antes del sobremuestreo\n",
    "    X_train_eval, X_test_eval, y_train_eval, y_test_eval = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # 6) Generar todas las combinaciones posibles entre los parÃ¡metros definidos\n",
    "    combinaciones = list(product(percentiles_densidad, percentiles_riesgo, criterios_pureza))\n",
    "\n",
    "    # 7) Iterar sobre cada combinaciÃ³n y aplicar sobremuestreo + entrenamiento + evaluaciÃ³n\n",
    "    for idx, (pdens, priesgo, criterio) in enumerate(combinaciones, start=1):\n",
    "        inicio = datetime.now()\n",
    "        print(f\"#{idx:02d} ğŸ§ª {nombre_modelo} | {nombre_dataset} | Densidad: {pdens} | Riesgo: {priesgo} | Pureza: {criterio}\")\n",
    "        print(f\"â±ï¸  Tiempo de inicio: {inicio.strftime('%H:%M:%S')} hs\")        \n",
    "\n",
    "        try:\n",
    "            # 7.a) Inicializar sampler PCSMOTE con los parÃ¡metros actuales\n",
    "            sampler = PCSMOTE(\n",
    "                random_state=42,\n",
    "                percentil_densidad=pdens,\n",
    "                percentil_dist=priesgo,\n",
    "                criterio_pureza=criterio,\n",
    "                modo_espacial='3d'  # Puede usarse '2d' si se desea modificar\n",
    "            )\n",
    "\n",
    "            # 7.b) Aplicar sobremuestreo sobre el set de entrenamiento (solo si mÃ©todo estÃ¡ definido)\n",
    "            if hasattr(sampler, \"fit_resample_multiclass\"):\n",
    "                X_res, y_res = sampler.fit_resample_multiclass(X_train_eval, y_train_eval)\n",
    "            else:\n",
    "                X_res, y_res = sampler.fit_resample(X_train_eval, y_train_eval)\n",
    "\n",
    "            # 7.c) Entrenar modelo sobre los datos aumentados\n",
    "            modelo_clasificador.fit(X_res, y_res)\n",
    "\n",
    "            # 7.d) Predecir sobre el set de evaluaciÃ³n (test)\n",
    "            y_pred = modelo_clasificador.predict(X_test_eval)\n",
    "\n",
    "            # 7.e) Calcular mÃ©tricas de rendimiento\n",
    "            f1_macro = f1_score(y_test_eval, y_pred, average='macro')\n",
    "            balanced_acc = balanced_accuracy_score(y_test_eval, y_pred)\n",
    "            mcc = matthews_corrcoef(y_test_eval, y_pred)\n",
    "            kappa = cohen_kappa_score(y_test_eval, y_pred)\n",
    "\n",
    "            # 7.f) Si hay clases minoritarias definidas, calcular tambiÃ©n f1_score sobre ellas\n",
    "            f1_minor = None\n",
    "            if clases_minor:\n",
    "                mask = np.isin(y_test_eval, clases_minor)\n",
    "                if np.any(mask):\n",
    "                    f1_minor = f1_score(y_test_eval[mask], y_pred[mask], average='macro')\n",
    "                    print(f\"ğŸ“Š f1_minor sobre {np.sum(mask)} muestras minoritarias.\")\n",
    "                    print(\"âœ”ï¸ Verdaderas:\", y_test_eval[mask])\n",
    "                    print(\"âŒ Predichas:\", y_pred[mask])\n",
    "\n",
    "            # 7.g) Mostrar resumen de rendimiento\n",
    "            print(f\"âœ… Config OK | F1_macro: {f1_macro:.4f}\" + (f\", F1_minor: {f1_minor:.4f}\" if f1_minor else \"\"))\n",
    "\n",
    "            # 7.h) Guardar resultados de esta corrida\n",
    "            resultados.append({\n",
    "                'dataset': nombre_dataset,\n",
    "                'modelo': nombre_modelo,\n",
    "                'densidad': pdens,\n",
    "                'riesgo': priesgo,\n",
    "                'pureza': criterio,\n",
    "                'f1_score_macro': f1_macro,\n",
    "                'f1_score_minor': f1_minor,\n",
    "                'balanced_accuracy': balanced_acc,\n",
    "                'mcc': mcc,\n",
    "                'cohen_kappa': kappa\n",
    "            })\n",
    "            \n",
    "            # 7.i) Mostrar tiempo de ejecuciÃ³n\n",
    "            fin = datetime.now()\n",
    "            transcurrido = fin - inicio\n",
    "            print(f\"âœ… Tiempo final: {fin.strftime('%H:%M:%S')} hs\")\n",
    "            print(f\"ğŸ•’ Total transcurrido: {str(transcurrido).rjust(8, '0')} hs\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # 8) En caso de error, registrar el fallo con detalles\n",
    "            print(f\"âš ï¸ Error con config D={pdens} R={priesgo} P={criterio}: {e}\")\n",
    "            resultados.append({\n",
    "                'dataset': nombre_dataset,\n",
    "                'modelo': nombre_modelo,\n",
    "                'densidad': pdens,\n",
    "                'riesgo': priesgo,\n",
    "                'pureza': criterio,\n",
    "                'f1_score_macro': None,\n",
    "                'f1_score_minor': None,\n",
    "                'balanced_accuracy': None,\n",
    "                'mcc': None,\n",
    "                'cohen_kappa': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "    # 9) Convertir resultados a DataFrame y exportar a CSV\n",
    "    df = pd.DataFrame(resultados)\n",
    "    df.to_csv(f\"../resultados/pcsmote_grid_{nombre_dataset}_{nombre_modelo}.csv\", index=False)\n",
    "    print(f\"ğŸ“ Resultados guardados en: ../resultados/pcsmote_grid_{nombre_dataset}_{nombre_modelo}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c754dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from config_datasets import config_datasets\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "\n",
    "tecnicas_sobremuestreo = {\n",
    "    # \"base\": None,\n",
    "    \"pcsmote\": PCSMOTE(\n",
    "        random_state=42,\n",
    "        percentil_densidad=50,  # serÃ¡n reemplazados dinÃ¡micamente en el grid\n",
    "        percentil_dist=50,\n",
    "        criterio_pureza='entropia',\n",
    "        modo_espacial='3d',\n",
    "        verbose=False\n",
    "    ),\n",
    "    # \"smote\": SMOTE(random_state=42),\n",
    "    # \"adasyn\": ADASYN(random_state=42),\n",
    "    # \"borderline\": BorderlineSMOTE(random_state=42)\n",
    "}\n",
    "\n",
    "modelos = {\n",
    "    # \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    # \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC(random_state=42)\n",
    "    # \"XGBoost\": XGBClassifier(...)  // esta fallando por la etiquetas\n",
    "}\n",
    "\n",
    "percentiles_densidad = [25, 50, 75]\n",
    "percentiles_riesgo = [25, 50, 75]\n",
    "criterios_pureza = [\"entropia\", \"proporcion\"]\n",
    "\n",
    "for nombre_dataset, config in config_datasets.items():\n",
    "    if nombre_dataset == \"eurosat\":\n",
    "        continue\n",
    "\n",
    "    if nombre_dataset == \"shuttle\":\n",
    "        for nombre_modelo, modelo in modelos.items():\n",
    "            for nombre_tec, tecnica in tecnicas_sobremuestreo.items():\n",
    "                print(f\"\\n=== Ejecutando grid para {nombre_dataset} | modelo: {nombre_modelo} | tÃ©cnica: {nombre_tec} ===\")\n",
    "\n",
    "                if nombre_tec == \"pcsmote\":\n",
    "\n",
    "\n",
    "                    evaluar_pcsmote_grid_search(\n",
    "                        nombre_dataset, config,\n",
    "                        percentiles_densidad, percentiles_riesgo,\n",
    "                        criterios_pureza, modelo, nombre_modelo\n",
    "                    )\n",
    "                # else:\n",
    "                #     evaluar_otra_tecnica_grid(\n",
    "                #         nombre_dataset, config, tecnica,\n",
    "                #         modelo, nombre_modelo, nombre_tec\n",
    "                #     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ca6ff",
   "metadata": {},
   "source": [
    "## Busqueda del mejor resultado para cada tecnica de sobremuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "datasets = ['shuttle']\n",
    "tecnicas = ['base', 'smote', 'adasyn', 'borderline', 'pcsmote']\n",
    "modelos = ['RandomForest', 'LogisticRegression', 'SVM']\n",
    "\n",
    "resumen = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    for tecnica in tecnicas:\n",
    "        archivos = glob.glob(f\"../resultados/{tecnica}_grid_{dataset}_*.csv\")\n",
    "        if not archivos:\n",
    "            print(f\"âš ï¸ No hay resultados para {dataset} con tÃ©cnica {tecnica}\")\n",
    "            continue\n",
    "\n",
    "        mejores_filas = []\n",
    "\n",
    "        for archivo in archivos:\n",
    "            try:\n",
    "                df = pd.read_csv(archivo)\n",
    "                df_valid = df.dropna(subset=[\"f1_score\"])\n",
    "                if df_valid.empty:\n",
    "                    continue\n",
    "\n",
    "                fila = df_valid.sort_values(by=\"f1_score\", ascending=False).iloc[0].copy()\n",
    "                fila['dataset'] = dataset\n",
    "                fila['tecnica'] = tecnica\n",
    "\n",
    "                nombre_archivo = os.path.basename(archivo)\n",
    "                modelo_detectado = next((m for m in modelos if m in nombre_archivo), \"desconocido\")\n",
    "                fila['modelo'] = modelo_detectado\n",
    "\n",
    "                mejores_filas.append(fila)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Error procesando {archivo}: {e}\")\n",
    "\n",
    "\n",
    "        # Guardar el mejor resultado por tÃ©cnica\n",
    "        if mejores_filas:\n",
    "            mejor = pd.DataFrame(mejores_filas).sort_values(by=\"f1_score\", ascending=False).iloc[0]\n",
    "            resumen.append(mejor)\n",
    "\n",
    "# Crear DataFrame final\n",
    "resumen_df = pd.DataFrame(resumen)\n",
    "\n",
    "# Reordenar columnas segÃºn disponibilidad\n",
    "cols = ['dataset', 'tecnica', 'modelo', 'f1_score']\n",
    "for col in ['balanced_accuracy', 'mcc', 'cohen_kappa', 'densidad', 'riesgo', 'pureza','error']:\n",
    "    if col in resumen_df.columns:\n",
    "        cols.append(col)\n",
    "\n",
    "resumen_df = resumen_df[cols]\n",
    "resumen_df.to_csv(\"../resultados/resumen_mejores_por_tecnica.csv\", index=False)\n",
    "print(\"âœ… Resumen guardado en ../resultados/resumen_mejores_por_tecnica.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e351ce",
   "metadata": {},
   "source": [
    "## Generacion de graficos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17140685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar el resumen\n",
    "df = pd.read_csv(\"../resultados/resumen_mejores_por_tecnica.csv\")\n",
    "\n",
    "# Ajustar orden de tÃ©cnicas para mejor visualizaciÃ³n\n",
    "orden_tecnicas = ['base', 'smote', 'adasyn', 'borderline', 'pcsmote']\n",
    "df['tecnica'] = pd.Categorical(df['tecnica'], categories=orden_tecnicas, ordered=True)\n",
    "\n",
    "# Plot por dataset\n",
    "for dataset in df['dataset'].unique():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df_sub = df[df['dataset'] == dataset].sort_values(\"tecnica\")\n",
    "\n",
    "    sns.barplot(\n",
    "        data=df_sub,\n",
    "        x=\"tecnica\",\n",
    "        y=\"f1_score\",\n",
    "        hue=\"modelo\",  # opcional: para ver quÃ© modelo dio ese resultado\n",
    "        dodge=False,\n",
    "        palette=\"viridis\"\n",
    "    )\n",
    "\n",
    "    plt.title(f\"F1-score por tÃ©cnica de sobremuestreo - {dataset}\")\n",
    "    plt.ylabel(\"F1-score\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.xlabel(\"TÃ©cnica\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
