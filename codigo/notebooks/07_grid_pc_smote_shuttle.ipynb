{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27267283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "sys.path.append(\"../datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee7abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cargar_dataset import cargar_dataset\n",
    "from config_datasets import config_datasets\n",
    "from evaluacion import evaluar_sampler_holdout\n",
    "from custom_samplers import PCSMOTEWrapper\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    f1_score, balanced_accuracy_score,\n",
    "    matthews_corrcoef, cohen_kappa_score\n",
    ")\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pc_smote import PCSMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, matthews_corrcoef, cohen_kappa_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d665899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # 👈 agregado\n",
    "\n",
    "def aumentar_dataset_pcsmote_y_guardar(nombre_dataset, config, percentil_densidad, percentil_riesgo, criterio_pureza, test_size=0.2):\n",
    "    print(f\"📂 Cargando dataset: {nombre_dataset}\")\n",
    "\n",
    "    try:\n",
    "        # 1) Cargar dataset original\n",
    "        X, y, clases = cargar_dataset(\n",
    "            path=config[\"path\"],\n",
    "            clase_minoria=config.get(\"clase_minoria\"),\n",
    "            col_features=config.get(\"col_features\"),\n",
    "            col_target=config.get(\"col_target\"),\n",
    "            sep=config.get(\"sep\", \",\"),\n",
    "            header=config.get(\"header\", None),\n",
    "            binarizar=False,\n",
    "            tipo=config.get(\"tipo\", \"tabular\")\n",
    "        )\n",
    "\n",
    "        # 2) Codificar etiquetas si son strings\n",
    "        if y.dtype == object or isinstance(y[0], str):\n",
    "            y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "        # 3) Si es un dataset de imágenes, convertir a vector plano\n",
    "        if config.get(\"tipo\") == \"imagen\":\n",
    "            X = X.reshape((X.shape[0], -1)).astype(np.float32)\n",
    "\n",
    "        # 4) Dividir en train/test (antes de sobremuestrear)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # 5) Escalar ambos usando estadísticas del train\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # 6) Aplicar PCSMOTE sobre el set de entrenamiento escalado\n",
    "        print(f\"🧬 Aplicando PCSMOTE | Densidad: {percentil_densidad} | Riesgo: {percentil_riesgo} | Pureza: {criterio_pureza}\")\n",
    "        sampler = PCSMOTE(\n",
    "            random_state=42,\n",
    "            percentil_densidad=percentil_densidad,\n",
    "            percentil_dist=percentil_riesgo,\n",
    "            criterio_pureza=criterio_pureza,\n",
    "            modo_espacial='3d'\n",
    "        )\n",
    "        sampler.nombre_dataset = nombre_dataset\n",
    "\n",
    "        if hasattr(sampler, \"fit_resample_multiclass\"):\n",
    "            X_train_res, y_train_res = sampler.fit_resample_multiclass(X_train, y_train)\n",
    "        else:\n",
    "            X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # 7) Guardar datasets: train aumentado y test escalado\n",
    "        print(f\"💾 Guardando datasets aumentados...\")\n",
    "\n",
    "        ruta_salida = f\"../datasets/datasets_aumentados/\"\n",
    "        os.makedirs(ruta_salida, exist_ok=True)\n",
    "\n",
    "        nombre_base = f\"pcsmote_{nombre_dataset}_D{percentil_densidad}_R{percentil_riesgo}_P{criterio_pureza}\"\n",
    "        path_train = os.path.join(ruta_salida, f\"{nombre_base}_train.csv\")\n",
    "        path_test = os.path.join(ruta_salida, f\"{nombre_base}_test.csv\")\n",
    "\n",
    "        # Guardar train aumentado\n",
    "        df_train = pd.DataFrame(X_train_res)\n",
    "        df_train[\"target\"] = y_train_res\n",
    "        df_train.to_csv(path_train, index=False)\n",
    "\n",
    "        # Guardar test escalado (sin sobremuestrear)\n",
    "        df_test = pd.DataFrame(X_test)\n",
    "        df_test[\"target\"] = y_test\n",
    "        df_test.to_csv(path_test, index=False)\n",
    "\n",
    "        print(f\"✅ Datasets guardados:\\n- Train aumentado: {path_train}\\n- Test escalado: {path_test}\")\n",
    "        return path_train, path_test, sampler\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al aumentar dataset {nombre_dataset}: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98760b9d",
   "metadata": {},
   "source": [
    "### 🧬 Aumento de Datasets mediante Técnicas de Sobremuestreo\n",
    "\n",
    "En esta etapa se genera una versión balanceada de cada dataset original mediante la aplicación de técnicas de sobremuestreo, con el objetivo de mitigar el desbalance de clases antes del entrenamiento de los modelos.\n",
    "\n",
    "Actualmente, se emplea la técnica:\n",
    "\n",
    "- `PCSMOTE` (Percentile-Controlled SMOTE), que permite controlar la generación de muestras sintéticas en función de percentiles de densidad, riesgo y pureza.\n",
    "\n",
    "Para cada dataset, se exploran combinaciones específicas de parámetros según la técnica utilizada. Los datasets resultantes se almacenan en el directorio `datasets/datasets_aumentados/`, utilizando nombres de archivo que reflejan la configuración empleada (por ejemplo: `pcsmote_nombre_D25_R50_Pentropia_train.csv`).\n",
    "\n",
    "> ⚠️ Esta fase no incluye entrenamiento ni validación de modelos. Su único propósito es generar conjuntos de datos aumentados a partir del conjunto de entrenamiento. La partición `train/test` se realiza previamente, y **solo la parte de entrenamiento es sometida a sobremuestreo**. El conjunto de prueba permanece sin modificar para garantizar una evaluación imparcial posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f74ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Dataset: shuttle\n",
      "#01 ➕ Aumentando con D=25 | R=25 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R25_Pentropia.csv\n",
      "#02 ➕ Aumentando con D=25 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R25_Pproporcion.csv\n",
      "#03 ➕ Aumentando con D=25 | R=50 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R50_Pentropia.csv\n",
      "#04 ➕ Aumentando con D=25 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R50_Pproporcion.csv\n",
      "#05 ➕ Aumentando con D=25 | R=75 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R75_Pentropia.csv\n",
      "#06 ➕ Aumentando con D=25 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D25_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D25_R75_Pproporcion.csv\n",
      "#07 ➕ Aumentando con D=50 | R=25 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R25_Pentropia.csv\n",
      "#08 ➕ Aumentando con D=50 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R25_Pproporcion.csv\n",
      "#09 ➕ Aumentando con D=50 | R=50 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R50_Pentropia.csv\n",
      "#10 ➕ Aumentando con D=50 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R50_Pproporcion.csv\n",
      "#11 ➕ Aumentando con D=50 | R=75 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R75_Pentropia.csv\n",
      "#12 ➕ Aumentando con D=50 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D50_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D50_R75_Pproporcion.csv\n",
      "#13 ➕ Aumentando con D=75 | R=25 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R25_Pentropia.csv\n",
      "#14 ➕ Aumentando con D=75 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R25_Pproporcion.csv\n",
      "#15 ➕ Aumentando con D=75 | R=50 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R50_Pentropia.csv\n",
      "#16 ➕ Aumentando con D=75 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R50_Pproporcion.csv\n",
      "#17 ➕ Aumentando con D=75 | R=75 | P=entropia\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R75_Pentropia.csv\n",
      "#18 ➕ Aumentando con D=75 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: shuttle\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_shuttle_D75_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_shuttle_D75_R75_Pproporcion.csv\n",
      "\n",
      "📁 Dataset: wdbc\n",
      "#01 ➕ Aumentando con D=25 | R=25 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R25_Pentropia.csv\n",
      "#02 ➕ Aumentando con D=25 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R25_Pproporcion.csv\n",
      "#03 ➕ Aumentando con D=25 | R=50 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R50_Pentropia.csv\n",
      "#04 ➕ Aumentando con D=25 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R50_Pproporcion.csv\n",
      "#05 ➕ Aumentando con D=25 | R=75 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R75_Pentropia.csv\n",
      "#06 ➕ Aumentando con D=25 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D25_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D25_R75_Pproporcion.csv\n",
      "#07 ➕ Aumentando con D=50 | R=25 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R25_Pentropia.csv\n",
      "#08 ➕ Aumentando con D=50 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R25_Pproporcion.csv\n",
      "#09 ➕ Aumentando con D=50 | R=50 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R50_Pentropia.csv\n",
      "#10 ➕ Aumentando con D=50 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R50_Pproporcion.csv\n",
      "#11 ➕ Aumentando con D=50 | R=75 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R75_Pentropia.csv\n",
      "#12 ➕ Aumentando con D=50 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D50_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D50_R75_Pproporcion.csv\n",
      "#13 ➕ Aumentando con D=75 | R=25 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R25_Pentropia.csv\n",
      "#14 ➕ Aumentando con D=75 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R25_Pproporcion.csv\n",
      "#15 ➕ Aumentando con D=75 | R=50 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R50_Pentropia.csv\n",
      "#16 ➕ Aumentando con D=75 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R50_Pproporcion.csv\n",
      "#17 ➕ Aumentando con D=75 | R=75 | P=entropia\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R75_Pentropia.csv\n",
      "#18 ➕ Aumentando con D=75 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: wdbc\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_wdbc_D75_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_wdbc_D75_R75_Pproporcion.csv\n",
      "\n",
      "📁 Dataset: glass\n",
      "#01 ➕ Aumentando con D=25 | R=25 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R25_Pentropia.csv\n",
      "#02 ➕ Aumentando con D=25 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R25_Pproporcion.csv\n",
      "#03 ➕ Aumentando con D=25 | R=50 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R50_Pentropia.csv\n",
      "#04 ➕ Aumentando con D=25 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R50_Pproporcion.csv\n",
      "#05 ➕ Aumentando con D=25 | R=75 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R75_Pentropia.csv\n",
      "#06 ➕ Aumentando con D=25 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D25_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D25_R75_Pproporcion.csv\n",
      "#07 ➕ Aumentando con D=50 | R=25 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R25_Pentropia.csv\n",
      "#08 ➕ Aumentando con D=50 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R25_Pproporcion.csv\n",
      "#09 ➕ Aumentando con D=50 | R=50 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R50_Pentropia.csv\n",
      "#10 ➕ Aumentando con D=50 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R50_Pproporcion.csv\n",
      "#11 ➕ Aumentando con D=50 | R=75 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R75_Pentropia.csv\n",
      "#12 ➕ Aumentando con D=50 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D50_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D50_R75_Pproporcion.csv\n",
      "#13 ➕ Aumentando con D=75 | R=25 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R25_Pentropia.csv\n",
      "#14 ➕ Aumentando con D=75 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R25_Pproporcion.csv\n",
      "#15 ➕ Aumentando con D=75 | R=50 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R50_Pentropia.csv\n",
      "#16 ➕ Aumentando con D=75 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R50_Pproporcion.csv\n",
      "#17 ➕ Aumentando con D=75 | R=75 | P=entropia\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R75_Pentropia.csv\n",
      "#18 ➕ Aumentando con D=75 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: glass\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_glass_D75_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_glass_D75_R75_Pproporcion.csv\n",
      "\n",
      "📁 Dataset: heart\n",
      "#01 ➕ Aumentando con D=25 | R=25 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R25_Pentropia.csv\n",
      "#02 ➕ Aumentando con D=25 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R25_Pproporcion.csv\n",
      "#03 ➕ Aumentando con D=25 | R=50 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R50_Pentropia.csv\n",
      "#04 ➕ Aumentando con D=25 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R50_Pproporcion.csv\n",
      "#05 ➕ Aumentando con D=25 | R=75 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R75_Pentropia.csv\n",
      "#06 ➕ Aumentando con D=25 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D25_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D25_R75_Pproporcion.csv\n",
      "#07 ➕ Aumentando con D=50 | R=25 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R25_Pentropia.csv\n",
      "#08 ➕ Aumentando con D=50 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R25_Pproporcion.csv\n",
      "#09 ➕ Aumentando con D=50 | R=50 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R50_Pentropia.csv\n",
      "#10 ➕ Aumentando con D=50 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R50_Pproporcion.csv\n",
      "#11 ➕ Aumentando con D=50 | R=75 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R75_Pentropia.csv\n",
      "#12 ➕ Aumentando con D=50 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D50_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D50_R75_Pproporcion.csv\n",
      "#13 ➕ Aumentando con D=75 | R=25 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R25_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R25_Pentropia.csv\n",
      "#14 ➕ Aumentando con D=75 | R=25 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R25_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R25_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R25_Pproporcion.csv\n",
      "#15 ➕ Aumentando con D=75 | R=50 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R50_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R50_Pentropia.csv\n",
      "#16 ➕ Aumentando con D=75 | R=50 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R50_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R50_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R50_Pproporcion.csv\n",
      "#17 ➕ Aumentando con D=75 | R=75 | P=entropia\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pentropia_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pentropia_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pentropia_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pentropia_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R75_Pentropia.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R75_Pentropia.csv\n",
      "#18 ➕ Aumentando con D=75 | R=75 | P=proporcion\n",
      "📂 Cargando dataset: heart\n",
      "⚠️ Advertencia: columnas no numéricas detectadas: [11, 12]\n",
      "🧬 Aplicando PCSMOTE | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "💾 Guardando datasets aumentados...\n",
      "✅ Datasets guardados:\n",
      "- Train aumentado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pproporcion_train.csv\n",
      "- Test escalado: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pproporcion_test.csv\n",
      "✅ Guardado exitoso:\n",
      " - Train: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pproporcion_train.csv\n",
      " - Test: ../datasets/datasets_aumentados/pcsmote_heart_D75_R75_Pproporcion_test.csv\n",
      "📁 Log de sobremuestreo guardado en: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R75_Pproporcion.csv\n",
      "📄 Log exportado: ../datasets/datasets_aumentados/logs/log_pcsmote_heart_D75_R75_Pproporcion.csv\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "\n",
    "percentiles_densidad = [25, 50, 75]\n",
    "percentiles_riesgo = [25, 50, 75]\n",
    "criterios_pureza = [\"entropia\", \"proporcion\"]\n",
    "\n",
    "# Generar todas las combinaciones del grid\n",
    "combinaciones = list(product(percentiles_densidad, percentiles_riesgo, criterios_pureza))\n",
    "\n",
    "# Asegurarse de que el directorio de logs exista\n",
    "os.makedirs(\"../logs/\", exist_ok=True)\n",
    "\n",
    "# Recorrer todos los datasets\n",
    "for nombre_dataset, config in config_datasets.items():\n",
    "    if nombre_dataset == \"eurosat\":\n",
    "        continue  # opcional: saltear imagenes si no estás trabajando con reshape 3D aún\n",
    "\n",
    "    print(f\"\\n📁 Dataset: {nombre_dataset}\")\n",
    "\n",
    "    for idx, (pdens, priesgo, criterio) in enumerate(combinaciones, start=1):\n",
    "        print(f\"#{idx:02d} ➕ Aumentando con D={pdens} | R={priesgo} | P={criterio}\")\n",
    "\n",
    "        # Ejecutar aumento y guardar resultados\n",
    "        path_train, path_test, sampler = aumentar_dataset_pcsmote_y_guardar(\n",
    "            nombre_dataset=nombre_dataset,\n",
    "            config=config,\n",
    "            percentil_densidad=pdens,\n",
    "            percentil_riesgo=priesgo,\n",
    "            criterio_pureza=criterio\n",
    "        )\n",
    "\n",
    "        if path_train and sampler:\n",
    "            print(f\"✅ Guardado exitoso:\\n - Train: {path_train}\\n - Test: {path_test}\")\n",
    "\n",
    "            # Guardar log por combinación\n",
    "            log_path = f\"../datasets/datasets_aumentados/logs/log_pcsmote_{nombre_dataset}_D{pdens}_R{priesgo}_P{criterio}.csv\"\n",
    "            sampler.exportar_log_csv(log_path)\n",
    "            print(f\"📄 Log exportado: {log_path}\")\n",
    "        else:\n",
    "            print(\"❌ Falló la generación.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc87fa1",
   "metadata": {},
   "source": [
    "### Evaluación de modelos con validación cruzada estratificada\n",
    "\n",
    "Para evaluar el rendimiento de los modelos de clasificación sobre los datasets previamente balanceados, se utilizó validación cruzada estratificada de 5 particiones (Stratified K-Fold con *k=5*). Este método garantiza que en cada fold de entrenamiento y validación se preserve la proporción original de clases, lo cual es especialmente importante en tareas de clasificación multiclase con datasets balanceados artificialmente.\n",
    "\n",
    "Durante el proceso, cada modelo es entrenado y evaluado cinco veces, cada vez usando un subconjunto distinto como conjunto de prueba y el resto como conjunto de entrenamiento. Las métricas calculadas en cada iteración (F1-score macro, balanced accuracy, MCC y kappa de Cohen) se promedian para obtener un valor representativo y del rendimiento general del modelo sobre ese dataset aumentado.\n",
    "\n",
    "Este enfoque evita sobreajuste y proporciona una evaluación más confiable que una simple división train/test, permitiendo comparar de forma justa distintas configuraciones de sobremuestreo y modelos de clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5320c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D25_R25_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D25_R25_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D25_R50_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D25_R50_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D25_R75_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D25_R75_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D50_R25_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D50_R25_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D50_R50_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D50_R50_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D50_R75_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D50_R75_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D75_R25_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D75_R25_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D75_R50_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D75_R50_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D75_R75_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_glass_D75_R75_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: glass | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D25_R25_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D25_R25_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D25_R50_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D25_R50_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D25_R75_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D25_R75_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 25 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D50_R25_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D50_R25_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D50_R50_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D50_R50_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D50_R75_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D50_R75_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 50 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D75_R25_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D75_R25_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 25 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D75_R50_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 50 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D75_R50_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 50 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D75_R75_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 75 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_heart_D75_R75_Pproporcion_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: heart | Densidad: 75 | Riesgo: 75 | Pureza: proporcion\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: LogisticRegression\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: RandomForest\n",
      "\n",
      "📂 Dataset aumentado: pcsmote_shuttle_D25_R25_Pentropia_train.csv\n",
      "🔎 Técnica: pcsmote | Dataset: shuttle | Densidad: 25 | Riesgo: 25 | Pureza: entropia\n",
      "⚙️ Validando modelo con Pipeline y RandomizedSearchCV: SVM\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 98\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     89\u001b[0m         estimator\u001b[38;5;241m=\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     90\u001b[0m         param_distributions\u001b[38;5;241m=\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_distributions\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     97\u001b[0m     )\n\u001b[1;32m---> 98\u001b[0m     \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     df_mean \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score_macro\u001b[39m\u001b[38;5;124m'\u001b[39m: search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_f1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m][search\u001b[38;5;241m.\u001b[39mbest_index_],\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_balanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][search\u001b[38;5;241m.\u001b[39mbest_index_],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmejor_configuracion\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m    112\u001b[0m     }\n\u001b[0;32m    114\u001b[0m     resultados_por_modelo[nombre_modelo]\u001b[38;5;241m.\u001b[39mappend(df_mean)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Modelos y sus espacios de hiperparámetros\n",
    "modelos = {\n",
    "    \"SVM\": {\n",
    "        \"pipeline\": Pipeline([\n",
    "            ('classifier', SVC(random_state=42))\n",
    "        ]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__C': uniform(0.1, 10),\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__gamma': ['scale', 'auto']\n",
    "        }\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"pipeline\": Pipeline([\n",
    "            ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "        ]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__C': uniform(0.1, 10),\n",
    "            'classifier__penalty': ['l2'],\n",
    "            'classifier__solver': ['lbfgs']\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"pipeline\": Pipeline([\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ]),\n",
    "        \"param_distributions\": {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ruta de datasets aumentados\n",
    "ruta = \"../datasets/datasets_aumentados/\"\n",
    "archivos = [f for f in os.listdir(ruta) if f.endswith(\"_train.csv\")]\n",
    "\n",
    "# Métricas personalizadas\n",
    "scoring = {\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'balanced_accuracy': 'balanced_accuracy',\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'cohen_kappa': make_scorer(cohen_kappa_score)\n",
    "}\n",
    "\n",
    "# Resultados acumulados\n",
    "resultados_por_modelo = {nombre: [] for nombre in modelos}\n",
    "\n",
    "# Evaluación por archivo CSV\n",
    "for archivo in archivos:\n",
    "    partes = archivo.replace(\".csv\", \"\").split(\"_\")\n",
    "    if len(partes) < 5:\n",
    "        print(f\"⚠️ Nombre de archivo inválido o incompleto: {archivo}\")\n",
    "        continue\n",
    "\n",
    "    tecnica = partes[0]\n",
    "    nombre_dataset = partes[1]\n",
    "    densidad = partes[2][1:]\n",
    "    riesgo = partes[3][1:]\n",
    "    pureza = partes[4][1:]\n",
    "\n",
    "    print(f\"\\n📂 Dataset aumentado: {archivo}\")\n",
    "    print(f\"🔎 Técnica: {tecnica} | Dataset: {nombre_dataset} | Densidad: {densidad} | Riesgo: {riesgo} | Pureza: {pureza}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(ruta, archivo))\n",
    "        X = df.drop(columns=[\"target\"]).values\n",
    "        y = df[\"target\"].values\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        for nombre_modelo, info in modelos.items():\n",
    "            print(f\"⚙️ Validando modelo con Pipeline y RandomizedSearchCV: {nombre_modelo}\")\n",
    "\n",
    "            try:\n",
    "                search = RandomizedSearchCV(\n",
    "                    estimator=info['pipeline'],\n",
    "                    param_distributions=info['param_distributions'],\n",
    "                    n_iter=10,\n",
    "                    cv=cv,\n",
    "                    scoring=scoring,\n",
    "                    refit='f1_macro',\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                search.fit(X, y)\n",
    "\n",
    "                df_mean = {\n",
    "                    'f1_score_macro': search.cv_results_['mean_test_f1_macro'][search.best_index_],\n",
    "                    'balanced_accuracy': search.cv_results_['mean_test_balanced_accuracy'][search.best_index_],\n",
    "                    'mcc': search.cv_results_['mean_test_mcc'][search.best_index_],\n",
    "                    'cohen_kappa': search.cv_results_['mean_test_cohen_kappa'][search.best_index_],\n",
    "                    'dataset': nombre_dataset,\n",
    "                    'tecnica': tecnica,\n",
    "                    'modelo': nombre_modelo,\n",
    "                    'densidad': densidad,\n",
    "                    'riesgo': riesgo,\n",
    "                    'pureza': pureza,\n",
    "                    'mejor_configuracion': str(search.best_params_)\n",
    "                }\n",
    "\n",
    "                resultados_por_modelo[nombre_modelo].append(df_mean)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error al validar modelo {nombre_modelo} en {archivo}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al procesar archivo {archivo}: {e}\")\n",
    "\n",
    "# Guardar resultados\n",
    "os.makedirs(\"../resultados\", exist_ok=True)\n",
    "for nombre_modelo, lista_resultados in resultados_por_modelo.items():\n",
    "    df_final = pd.DataFrame(lista_resultados)\n",
    "    output_path = f\"../resultados/resultados_{nombre_modelo}.csv\"\n",
    "    df_final.to_csv(output_path, index=False)\n",
    "    print(f\"📁 Resultados guardados: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb30cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_otra_tecnica_grid(nombre_dataset, config, tecnica, modelo_clasificador, nombre_modelo, nombre_tec):\n",
    "    print(f\"📂 Cargando dataset: {nombre_dataset}\")\n",
    "    X, y, _ = cargar_dataset(\n",
    "        path=config[\"path\"],\n",
    "        clase_minoria=config.get(\"clase_minoria\"),\n",
    "        col_features=config.get(\"col_features\"),\n",
    "        col_target=config.get(\"col_target\"),\n",
    "        sep=config.get(\"sep\", \",\"),\n",
    "        header=config.get(\"header\", None),\n",
    "        binarizar=False,\n",
    "        tipo=config.get(\"tipo\", \"tabular\")\n",
    "    )\n",
    "\n",
    "    if y.dtype == object or isinstance(y[0], str):\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    if config.get(\"tipo\") == \"imagen\":\n",
    "        X = X.reshape((X.shape[0], -1)).astype(np.float32)\n",
    "\n",
    "    clases_minor = config.get(\"clases_minor\", [])\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    metricas_fold = []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"🔁 Fold {fold_idx + 1}/5\")\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        pca = PCA(n_components=min(X_train.shape[1], 100))\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        try:\n",
    "            if tecnica:\n",
    "                X_res, y_res = tecnica.fit_resample(X_train_pca, y_train)\n",
    "            else:\n",
    "                X_res, y_res = X_train_pca, y_train\n",
    "\n",
    "            modelo_escalado = get_modelo_escalado_si_es_necesario(modelo_clasificador, nombre_modelo)\n",
    "            modelo_escalado.fit(X_res, y_res)\n",
    "            y_pred = modelo_escalado.predict(X_test_pca)\n",
    "\n",
    "            f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "            balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "            kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "            f1_minor = None\n",
    "            if clases_minor:\n",
    "                mask = np.isin(y_test, clases_minor)\n",
    "                if np.any(mask):\n",
    "                    f1_minor = f1_score(y_test[mask], y_pred[mask], average='macro')\n",
    "\n",
    "            metricas_fold.append({\n",
    "                'f1_score_macro': f1_macro,\n",
    "                'f1_score_minor': f1_minor,\n",
    "                'balanced_accuracy': balanced_acc,\n",
    "                'mcc': mcc,\n",
    "                'cohen_kappa': kappa\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error en fold {fold_idx + 1}: {e}\")\n",
    "            metricas_fold.append({\n",
    "                'f1_score_macro': None,\n",
    "                'f1_score_minor': None,\n",
    "                'balanced_accuracy': None,\n",
    "                'mcc': None,\n",
    "                'cohen_kappa': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "    df_metricas = pd.DataFrame(metricas_fold)\n",
    "    df_mean = df_metricas.dropna().mean(numeric_only=True).to_dict()\n",
    "    df_mean.update({\n",
    "        'dataset': nombre_dataset,\n",
    "        'modelo': nombre_modelo,\n",
    "        'tecnica': nombre_tec\n",
    "    })\n",
    "\n",
    "    df_final = pd.DataFrame([df_mean])\n",
    "    df_final.to_csv(f\"../resultados/{nombre_tec}_grid_{nombre_dataset}_{nombre_modelo}.csv\", index=False)\n",
    "    print(f\"📁 Resultados guardados en: ../resultados/{nombre_tec}_grid_{nombre_dataset}_{nombre_modelo}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluar_pcsmote_grid_search(nombre_dataset, config, percentiles_densidad, percentiles_riesgo, criterios_pureza, modelo_clasificador, nombre_modelo):\n",
    "    print(f\"📂 Cargando dataset: {nombre_dataset}\")\n",
    "\n",
    "    # 1) Cargar dataset según los parámetros recibidos (ruta, columnas, tipo, etc.)\n",
    "    X, y, _ = cargar_dataset(\n",
    "        path=config[\"path\"],\n",
    "        clase_minoria=config.get(\"clase_minoria\"),\n",
    "        col_features=config.get(\"col_features\"),\n",
    "        col_target=config.get(\"col_target\"),\n",
    "        sep=config.get(\"sep\", \",\"),\n",
    "        header=config.get(\"header\", None),\n",
    "        binarizar=False,\n",
    "        tipo=config.get(\"tipo\", \"tabular\")\n",
    "    )\n",
    "\n",
    "    # 2) Codificar etiquetas si son strings u objetos\n",
    "    if y.dtype == object or isinstance(y[0], str):  \n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    # 3) Si es un dataset de imágenes, aplastar (reshape) cada imagen a vector 1D\n",
    "    # Esto convierte (N, H, W, C) en (N, H*W*C) para trabajar como tabular\n",
    "    if config.get(\"tipo\") == \"imagen\":\n",
    "        X = X.reshape((X.shape[0], -1)).astype(np.float32)\n",
    "\n",
    "    # 4) Obtener clases minoritarias si están definidas\n",
    "    clases_minor = config.get(\"clases_minor\", [])\n",
    "    resultados = []\n",
    "\n",
    "    # 5) Dividir en train/test con estratificación, antes del sobremuestreo\n",
    "    X_train_eval, X_test_eval, y_train_eval, y_test_eval = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # 6) Generar todas las combinaciones posibles entre los parámetros definidos\n",
    "    combinaciones = list(product(percentiles_densidad, percentiles_riesgo, criterios_pureza))\n",
    "\n",
    "    # 7) Iterar sobre cada combinación y aplicar sobremuestreo + entrenamiento + evaluación\n",
    "    for idx, (pdens, priesgo, criterio) in enumerate(combinaciones, start=1):\n",
    "        inicio = datetime.now()\n",
    "        print(f\"#{idx:02d} 🧪 {nombre_modelo} | {nombre_dataset} | Densidad: {pdens} | Riesgo: {priesgo} | Pureza: {criterio}\")\n",
    "        print(f\"⏱️  Tiempo de inicio: {inicio.strftime('%H:%M:%S')} hs\")        \n",
    "\n",
    "        try:\n",
    "            # 7.a) Inicializar sampler PCSMOTE con los parámetros actuales\n",
    "            sampler = PCSMOTE(\n",
    "                random_state=42,\n",
    "                percentil_densidad=pdens,\n",
    "                percentil_dist=priesgo,\n",
    "                criterio_pureza=criterio,\n",
    "                modo_espacial='3d'  # Puede usarse '2d' si se desea modificar\n",
    "            )\n",
    "\n",
    "            # 7.b) Aplicar sobremuestreo sobre el set de entrenamiento (solo si método está definido)\n",
    "            if hasattr(sampler, \"fit_resample_multiclass\"):\n",
    "                X_res, y_res = sampler.fit_resample_multiclass(X_train_eval, y_train_eval)\n",
    "            else:\n",
    "                X_res, y_res = sampler.fit_resample(X_train_eval, y_train_eval)\n",
    "\n",
    "            # 7.c) Entrenar modelo sobre los datos aumentados\n",
    "            modelo_clasificador.fit(X_res, y_res)\n",
    "\n",
    "            # 7.d) Predecir sobre el set de evaluación (test)\n",
    "            y_pred = modelo_clasificador.predict(X_test_eval)\n",
    "\n",
    "            # 7.e) Calcular métricas de rendimiento\n",
    "            f1_macro = f1_score(y_test_eval, y_pred, average='macro')\n",
    "            balanced_acc = balanced_accuracy_score(y_test_eval, y_pred)\n",
    "            mcc = matthews_corrcoef(y_test_eval, y_pred)\n",
    "            kappa = cohen_kappa_score(y_test_eval, y_pred)\n",
    "\n",
    "            # 7.f) Si hay clases minoritarias definidas, calcular también f1_score sobre ellas\n",
    "            f1_minor = None\n",
    "            if clases_minor:\n",
    "                mask = np.isin(y_test_eval, clases_minor)\n",
    "                if np.any(mask):\n",
    "                    f1_minor = f1_score(y_test_eval[mask], y_pred[mask], average='macro')\n",
    "                    print(f\"📊 f1_minor sobre {np.sum(mask)} muestras minoritarias.\")\n",
    "                    print(\"✔️ Verdaderas:\", y_test_eval[mask])\n",
    "                    print(\"❌ Predichas:\", y_pred[mask])\n",
    "\n",
    "            # 7.g) Mostrar resumen de rendimiento\n",
    "            print(f\"✅ Config OK | F1_macro: {f1_macro:.4f}\" + (f\", F1_minor: {f1_minor:.4f}\" if f1_minor else \"\"))\n",
    "\n",
    "            # 7.h) Guardar resultados de esta corrida\n",
    "            resultados.append({\n",
    "                'dataset': nombre_dataset,\n",
    "                'modelo': nombre_modelo,\n",
    "                'densidad': pdens,\n",
    "                'riesgo': priesgo,\n",
    "                'pureza': criterio,\n",
    "                'f1_score_macro': f1_macro,\n",
    "                'f1_score_minor': f1_minor,\n",
    "                'balanced_accuracy': balanced_acc,\n",
    "                'mcc': mcc,\n",
    "                'cohen_kappa': kappa\n",
    "            })\n",
    "            \n",
    "            # 7.i) Mostrar tiempo de ejecución\n",
    "            fin = datetime.now()\n",
    "            transcurrido = fin - inicio\n",
    "            print(f\"✅ Tiempo final: {fin.strftime('%H:%M:%S')} hs\")\n",
    "            print(f\"🕒 Total transcurrido: {str(transcurrido).rjust(8, '0')} hs\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # 8) En caso de error, registrar el fallo con detalles\n",
    "            print(f\"⚠️ Error con config D={pdens} R={priesgo} P={criterio}: {e}\")\n",
    "            resultados.append({\n",
    "                'dataset': nombre_dataset,\n",
    "                'modelo': nombre_modelo,\n",
    "                'densidad': pdens,\n",
    "                'riesgo': priesgo,\n",
    "                'pureza': criterio,\n",
    "                'f1_score_macro': None,\n",
    "                'f1_score_minor': None,\n",
    "                'balanced_accuracy': None,\n",
    "                'mcc': None,\n",
    "                'cohen_kappa': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "    # 9) Convertir resultados a DataFrame y exportar a CSV\n",
    "    df = pd.DataFrame(resultados)\n",
    "    df.to_csv(f\"../resultados/pcsmote_grid_{nombre_dataset}_{nombre_modelo}.csv\", index=False)\n",
    "    print(f\"📁 Resultados guardados en: ../resultados/pcsmote_grid_{nombre_dataset}_{nombre_modelo}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c754dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from config_datasets import config_datasets\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "\n",
    "tecnicas_sobremuestreo = {\n",
    "    # \"base\": None,\n",
    "    \"pcsmote\": PCSMOTE(\n",
    "        random_state=42,\n",
    "        percentil_densidad=50,  # serán reemplazados dinámicamente en el grid\n",
    "        percentil_dist=50,\n",
    "        criterio_pureza='entropia',\n",
    "        modo_espacial='3d',\n",
    "        verbose=False\n",
    "    ),\n",
    "    # \"smote\": SMOTE(random_state=42),\n",
    "    # \"adasyn\": ADASYN(random_state=42),\n",
    "    # \"borderline\": BorderlineSMOTE(random_state=42)\n",
    "}\n",
    "\n",
    "modelos = {\n",
    "    # \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    # \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC(random_state=42)\n",
    "    # \"XGBoost\": XGBClassifier(...)  // esta fallando por la etiquetas\n",
    "}\n",
    "\n",
    "percentiles_densidad = [25, 50, 75]\n",
    "percentiles_riesgo = [25, 50, 75]\n",
    "criterios_pureza = [\"entropia\", \"proporcion\"]\n",
    "\n",
    "for nombre_dataset, config in config_datasets.items():\n",
    "    if nombre_dataset == \"eurosat\":\n",
    "        continue\n",
    "\n",
    "    if nombre_dataset == \"shuttle\":\n",
    "        for nombre_modelo, modelo in modelos.items():\n",
    "            for nombre_tec, tecnica in tecnicas_sobremuestreo.items():\n",
    "                print(f\"\\n=== Ejecutando grid para {nombre_dataset} | modelo: {nombre_modelo} | técnica: {nombre_tec} ===\")\n",
    "\n",
    "                if nombre_tec == \"pcsmote\":\n",
    "\n",
    "\n",
    "                    evaluar_pcsmote_grid_search(\n",
    "                        nombre_dataset, config,\n",
    "                        percentiles_densidad, percentiles_riesgo,\n",
    "                        criterios_pureza, modelo, nombre_modelo\n",
    "                    )\n",
    "                # else:\n",
    "                #     evaluar_otra_tecnica_grid(\n",
    "                #         nombre_dataset, config, tecnica,\n",
    "                #         modelo, nombre_modelo, nombre_tec\n",
    "                #     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ca6ff",
   "metadata": {},
   "source": [
    "## Busqueda del mejor resultado para cada tecnica de sobremuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "datasets = ['shuttle']\n",
    "tecnicas = ['base', 'smote', 'adasyn', 'borderline', 'pcsmote']\n",
    "modelos = ['RandomForest', 'LogisticRegression', 'SVM']\n",
    "\n",
    "resumen = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    for tecnica in tecnicas:\n",
    "        archivos = glob.glob(f\"../resultados/{tecnica}_grid_{dataset}_*.csv\")\n",
    "        if not archivos:\n",
    "            print(f\"⚠️ No hay resultados para {dataset} con técnica {tecnica}\")\n",
    "            continue\n",
    "\n",
    "        mejores_filas = []\n",
    "\n",
    "        for archivo in archivos:\n",
    "            try:\n",
    "                df = pd.read_csv(archivo)\n",
    "                df_valid = df.dropna(subset=[\"f1_score\"])\n",
    "                if df_valid.empty:\n",
    "                    continue\n",
    "\n",
    "                fila = df_valid.sort_values(by=\"f1_score\", ascending=False).iloc[0].copy()\n",
    "                fila['dataset'] = dataset\n",
    "                fila['tecnica'] = tecnica\n",
    "\n",
    "                nombre_archivo = os.path.basename(archivo)\n",
    "                modelo_detectado = next((m for m in modelos if m in nombre_archivo), \"desconocido\")\n",
    "                fila['modelo'] = modelo_detectado\n",
    "\n",
    "                mejores_filas.append(fila)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error procesando {archivo}: {e}\")\n",
    "\n",
    "\n",
    "        # Guardar el mejor resultado por técnica\n",
    "        if mejores_filas:\n",
    "            mejor = pd.DataFrame(mejores_filas).sort_values(by=\"f1_score\", ascending=False).iloc[0]\n",
    "            resumen.append(mejor)\n",
    "\n",
    "# Crear DataFrame final\n",
    "resumen_df = pd.DataFrame(resumen)\n",
    "\n",
    "# Reordenar columnas según disponibilidad\n",
    "cols = ['dataset', 'tecnica', 'modelo', 'f1_score']\n",
    "for col in ['balanced_accuracy', 'mcc', 'cohen_kappa', 'densidad', 'riesgo', 'pureza','error']:\n",
    "    if col in resumen_df.columns:\n",
    "        cols.append(col)\n",
    "\n",
    "resumen_df = resumen_df[cols]\n",
    "resumen_df.to_csv(\"../resultados/resumen_mejores_por_tecnica.csv\", index=False)\n",
    "print(\"✅ Resumen guardado en ../resultados/resumen_mejores_por_tecnica.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e351ce",
   "metadata": {},
   "source": [
    "## Generacion de graficos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17140685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar el resumen\n",
    "df = pd.read_csv(\"../resultados/resumen_mejores_por_tecnica.csv\")\n",
    "\n",
    "# Ajustar orden de técnicas para mejor visualización\n",
    "orden_tecnicas = ['base', 'smote', 'adasyn', 'borderline', 'pcsmote']\n",
    "df['tecnica'] = pd.Categorical(df['tecnica'], categories=orden_tecnicas, ordered=True)\n",
    "\n",
    "# Plot por dataset\n",
    "for dataset in df['dataset'].unique():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df_sub = df[df['dataset'] == dataset].sort_values(\"tecnica\")\n",
    "\n",
    "    sns.barplot(\n",
    "        data=df_sub,\n",
    "        x=\"tecnica\",\n",
    "        y=\"f1_score\",\n",
    "        hue=\"modelo\",  # opcional: para ver qué modelo dio ese resultado\n",
    "        dodge=False,\n",
    "        palette=\"viridis\"\n",
    "    )\n",
    "\n",
    "    plt.title(f\"F1-score por técnica de sobremuestreo - {dataset}\")\n",
    "    plt.ylabel(\"F1-score\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.xlabel(\"Técnica\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
